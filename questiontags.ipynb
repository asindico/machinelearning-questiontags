{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Questions Automatic Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Capstone Project of my Udacity Machine Learning Nano Degree.\n",
    "\n",
    "In this capstone project I will focus on one specific kind of problem among the many open problems in NLP: Text Classification. The task is to state what is the topic, among several availables, of a content expressed in natural language. To this end I will rely on the questions shared by Stack Exchange , take three classes of questions (i.e. cooking, robotics, biology) and try to create a model capable of stating to what of these three classes an unknown question belongs. After that I will try to create a model that for the questions of a given topic tries to predict what are the tags that best describe it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    \"cooking\": pd.read_csv(\"cooking.csv\"),\n",
    "    \"biology\": pd.read_csv(\"biology.csv\"),\n",
    "    \"robotics\": pd.read_csv(\"robotics.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes['cooking']['class'] = 'cooking'\n",
    "dataframes['biology']['class'] = 'biology'\n",
    "dataframes['robotics']['class'] = 'robotics'\n",
    "\n",
    "allquestions = pd.concat([dataframes['cooking'][:5000],dataframes['robotics'],dataframes['biology'][:5000]],\n",
    "                        ignore_index=True)\n",
    "#allquestions = allquestions.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                         2\n",
      "title                    How should I cook bacon in an oven?\n",
      "content    <p>I've heard of people cooking bacon in an ov...\n",
      "tags                                 oven cooking-time bacon\n",
      "class                                                cooking\n",
      "Name: 1, dtype: object\n",
      "id                                                         2\n",
      "title      How can I modify a low cost hobby servo to run...\n",
      "content    <p>I've got some hobby servos (<a href=\"http:/...\n",
      "tags                                         control rcservo\n",
      "class                                               robotics\n",
      "Name: 1, dtype: object\n",
      "id                                                         2\n",
      "title      How is RNAse contamination in RNA based experi...\n",
      "content    <p>Does anyone have any suggestions to prevent...\n",
      "tags                                        rna biochemistry\n",
      "class                                                biology\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].iloc[1])\n",
    "print(dataframes[\"robotics\"].iloc[1])\n",
    "print(dataframes[\"biology\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15404, 5)\n",
      "['baking', 'food-safety', 'substitutions', 'equipment', 'bread']\n",
      "[1444, 1211, 920, 816, 687]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBESOAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10af60050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].shape)\n",
    "ctags = [ti for ta in dataframes[\"cooking\"].tags for ti in ta.split() ]\n",
    "cseries = pd.Series(ctags)\n",
    "cus = cseries.unique()\n",
    "counter = Counter(cseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "print(cus.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 5)\n",
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor']\n",
      "[306, 295, 282, 255, 239]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBUxNEiSpCKGBkmSVOT/A3Gunpk67gabAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1042cc450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"robotics\"].shape)\n",
    "rtags = [ti for ta in dataframes[\"robotics\"].tags for ti in ta.split() ]\n",
    "rseries = pd.Series(rtags)\n",
    "counter = Counter(rseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "rdf = pd.DataFrame(counter)\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "rus = rseries.unique()\n",
    "print(rus.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13196, 5)\n",
      "['human-biology', 'genetics', 'evolution', 'biochemistry', 'molecular-biology']\n",
      "[1448, 1229, 1159, 984, 863]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1042a0890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"biology\"].shape)\n",
    "btags = [ti for ta in dataframes[\"biology\"].tags for ti in ta.split() ]\n",
    "bseries = pd.Series(btags)\n",
    "counter = Counter(bseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "bus = bseries.unique()\n",
    "print(bus.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is transforming the input text into something that is machine readble which basically means numbers. \n",
    "We have to drop all the elemnts that do not provide relevant information. Since questions titles may contains html tags and uris we have to remove them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n",
    "def stripTagsAndUris(x):\n",
    "    if x:\n",
    "        soup = BeautifulSoup(x, \"html.parser\")\n",
    "        if soup.code:\n",
    "            soup.code.decompose()\n",
    "        text =  soup.get_text()\n",
    "        return re.sub(uri_re, \"\", text)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removePunctuation(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "def removeStopwords(x):\n",
    "    filtered_words = [word for word in x.split() if word not in stops]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textprep(_df):\n",
    "    for df in _df.values():\n",
    "        df[\"title\"] = df[\"title\"].map(removePunctuation)\n",
    "        df[\"title\"] = df[\"title\"].map(removeStopwords)\n",
    "        df[\"content\"] = df[\"content\"].map(removePunctuation)\n",
    "        df[\"content\"] = df[\"content\"].map(removeStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textprep(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                           2\n",
      "title                          cook bacon oven\n",
      "content    how should i cook bacon in an oven \n",
      "tags                   oven cooking-time bacon\n",
      "class                                  cooking\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest approach is the so called Bag-of-words model where the text is represented by the set of words contained in it, loosing their order and thus disregarding the grammar or the syntax. Each word is paired with an integer representing the occurrencies of that word in the represented text. One of the weak aspect of this approach is that longer text may present more occurrencies of a given word, with respect to a shorter text, not because of its relevance but just because the text is longer. \n",
    "\n",
    "Since we rely in titles, which are short by construction, I think this aspect will not affect our task.\n",
    "\n",
    "We rely on scikit learn CountVectorizer to transform words into numbers. We use a custom token pattern in order to catch words containing the '-' character like 'cooking-time'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing cooking titles\n",
      "vectorizing robotics titles\n",
      "vectorizing biology titles\n",
      "vectorizing cooking tags\n",
      "vectorizing robotics tags\n",
      "vectorizing biology tags\n",
      "vectorizing all titles\n"
     ]
    }
   ],
   "source": [
    "c_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "c_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "b_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "b_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "\n",
    "a_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "a_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "\n",
    "c_titles = dataframes['cooking']['title']\n",
    "r_titles = dataframes['robotics']['title']\n",
    "b_titles = dataframes['biology']['title']\n",
    "\n",
    "c_tags = dataframes['cooking']['tags']\n",
    "r_tags = dataframes['robotics']['tags']\n",
    "b_tags = dataframes['biology']['tags']\n",
    "\n",
    "a_titles  = allquestions['title']\n",
    "a_classes = allquestions['class']\n",
    "\n",
    "print \"vectorizing cooking titles\"\n",
    "c_X = c_title_vectorizer.fit_transform(c_titles)\n",
    "print \"vectorizing robotics titles\"\n",
    "r_X = r_title_vectorizer.fit_transform(r_titles)\n",
    "print \"vectorizing biology titles\"\n",
    "b_X = b_title_vectorizer.fit_transform(b_titles)\n",
    "\n",
    "print \"vectorizing cooking tags\"\n",
    "c_Y = c_tag_vectorizer.fit_transform(c_tags)\n",
    "print \"vectorizing robotics tags\"\n",
    "r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "print \"vectorizing biology tags\"\n",
    "b_Y = b_tag_vectorizer.fit_transform(b_tags)\n",
    "\n",
    "print \"vectorizing all titles\"\n",
    "a_X = a_title_vectorizer.fit_transform(a_titles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2573)\t1\n",
      "  (0, 1974)\t1\n",
      "  (0, 1990)\t1\n",
      "  (0, 1937)\t1\n"
     ]
    }
   ],
   "source": [
    "print(a_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of single words like the bag-of-words fail capture phrases and expressions of multiple words. A more valuable approch is to consider single words along with sequences of adjcent words called n-grams. In this project we use bi-grams as a possible input model. Fortunately the CountVectorizer class can be configured to extract any range of ngram with the ngram_range(min,max) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing all titles with 3-grams\n"
     ]
    }
   ],
   "source": [
    "ang_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing all titles with 2-grams\"\n",
    "a_X_2g = ang_title_vectorizer.fit_transform(a_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8358)\t1\n",
      "  (0, 8419)\t1\n",
      "  (0, 8143)\t1\n",
      "  (0, 11082)\t1\n",
      "  (0, 8355)\t1\n",
      "  (0, 8405)\t1\n",
      "  (0, 8141)\t1\n"
     ]
    }
   ],
   "source": [
    "print(a_X_2g[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated approach is to rely on vector space representations of words. Basically the idea is to exploit a previously created lookup table in which, for each word of our vocabulary, a vector of float valus corresponds. Their interesting property is that two words with similar meaning have similar vectors. These vectors are generally created automatically with a separated machine learning approach on big corpus of texts. \n",
    "In this project we rely on an already exsiting vector space called Glove.\n",
    "\n",
    "https://nlp.stanford.edu/pubs/glove.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = {}\n",
    "with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here follows an example of what the pre-trained data can be used to retrieve vectors of values for each single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68163   1.1578   -0.47827   0.41421  -0.53186   0.63827  -0.90381\n",
      "  0.50795   0.057398 -0.29163   1.1411   -0.079702  0.19951   1.1925\n",
      "  0.52281   0.78633   0.78555   0.32624  -1.5504   -1.0191    0.35532\n",
      " -0.38875   0.92789   0.24325  -0.43162  -0.54939  -0.52209   1.0721\n",
      "  0.99558  -0.38605   2.2673    0.41067  -0.08973   0.29741  -0.18678\n",
      "  0.44329  -0.42243   0.80558   1.1306    0.14038  -0.089723  0.1341\n",
      "  0.47948  -0.12774   0.024234  0.051782  0.44778  -0.47974  -0.62491\n",
      " -0.90005 ]\n"
     ]
    }
   ],
   "source": [
    "keys= w2v.keys()\n",
    "print (w2v['ice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_Xe = []\n",
    "for title in a_titles:\n",
    "    sentence = []\n",
    "    for word in title.split():\n",
    "        if word in w2v:\n",
    "            wv = w2v[word]\n",
    "            sentence.append(wv)\n",
    "    words = [w for s in sentence for w in s]\n",
    "    a_Xe.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "maxdim = 0\n",
    "for s in a_Xe:\n",
    "    if len(s)>maxdim:\n",
    "        maxdim = len(s)\n",
    "print maxdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for sent in a_Xe:\n",
    "    padd = [0 for _ in range (maxdim - len(sent))]\n",
    "    padd = np.asarray(padd)\n",
    "    paddedsent = np.concatenate((sent,padd),axis=0)\n",
    "    sentences.append(paddedsent)\n",
    "a_Xe = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35145   -0.24155    0.0054776 ...,  0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "print a_Xe[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Problem: Questions Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first problem I will try to create a model capable of stating, given an unknown question, to what class it belongs. I will try Naive Bayes and Random Forest on input data modeled through Bag of Words, n-grams (with n = 2) and word vectors (Glove). In the third case I will also try to train a Convolutional Neural Network. \n",
    "\n",
    "I will compare the obtained 7 models through the F1score metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12771, 12661)\n"
     ]
    }
   ],
   "source": [
    "print a_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a_X.toarray(), a_classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology\n",
      "biology\n"
     ]
    }
   ],
   "source": [
    "idx = 351\n",
    "print np.array(y_test)[idx]\n",
    "print y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887763885977\n"
     ]
    }
   ],
   "source": [
    "fs1_1 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877509953024\n"
     ]
    }
   ],
   "source": [
    "fs1_2 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12771, 55882)\n",
      "(12771,)\n"
     ]
    }
   ],
   "source": [
    "a_X_2g_array = a_X_2g.toarray()\n",
    "print(a_X_2g_array.shape)\n",
    "print(a_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3g_train, X3g_test, y3g_train, y3g_test = train_test_split(a_X_2g_array, a_classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb3 = GaussianNB()\n",
    "y_pred = gnb3.fit(X3g_train, y3g_train).predict(X3g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896844697847\n"
     ]
    }
   ],
   "source": [
    "fs1_3 = f1_score(np.array(y3g_test), y_pred, average='macro') \n",
    "print fs1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X3g_train, y3g_train).predict(X3g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878467432249\n"
     ]
    }
   ],
   "source": [
    "fs1_4 = f1_score(np.array(y3g_test), y_pred, average='macro') \n",
    "print fs1_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_classes = a_classes.str.get_dummies()\n",
    "#print cat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a_Xe, a_classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(a_Xe, cat_classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.149552249279\n"
     ]
    }
   ],
   "source": [
    "fs1_5 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707805926699\n"
     ]
    }
   ],
   "source": [
    "fs1_6 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3970 - acc: 0.8319    \n",
      "Epoch 2/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3860 - acc: 0.8365    \n",
      "Epoch 3/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3733 - acc: 0.8375    \n",
      "Epoch 4/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3636 - acc: 0.8434    \n",
      "Epoch 5/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3514 - acc: 0.8511    \n",
      "Epoch 6/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3424 - acc: 0.8574    \n",
      "Epoch 7/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3318 - acc: 0.8620    \n",
      "Epoch 8/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3217 - acc: 0.8622    \n",
      "Epoch 9/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3111 - acc: 0.8717    \n",
      "Epoch 10/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3039 - acc: 0.8706    \n",
      "Epoch 11/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2952 - acc: 0.8742    \n",
      "Epoch 12/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2838 - acc: 0.8793    \n",
      "Epoch 13/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2774 - acc: 0.8828    \n",
      "Epoch 14/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2734 - acc: 0.8852    \n",
      "Epoch 15/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2631 - acc: 0.8891    \n",
      "Epoch 16/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.2551 - acc: 0.8928    \n",
      "Epoch 17/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2487 - acc: 0.8946    \n",
      "Epoch 18/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2442 - acc: 0.8977    \n",
      "Epoch 19/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2338 - acc: 0.9017    \n",
      "Epoch 20/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.2270 - acc: 0.9038    \n",
      "Epoch 21/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2215 - acc: 0.9050    \n",
      "Epoch 22/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.2186 - acc: 0.9047    \n",
      "Epoch 23/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2123 - acc: 0.9090    \n",
      "Epoch 24/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.2046 - acc: 0.9113    \n",
      "Epoch 25/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.1995 - acc: 0.9140    \n",
      "Epoch 26/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.1968 - acc: 0.9154    \n",
      "Epoch 27/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.1903 - acc: 0.9156    \n",
      "Epoch 28/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.1902 - acc: 0.9182    \n",
      "Epoch 29/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1854 - acc: 0.9184    \n",
      "Epoch 30/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1814 - acc: 0.9213    \n",
      "Epoch 31/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1754 - acc: 0.9237    \n",
      "Epoch 32/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1761 - acc: 0.9247    \n",
      "Epoch 33/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1683 - acc: 0.9279    \n",
      "Epoch 34/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1672 - acc: 0.9264    \n",
      "Epoch 35/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1619 - acc: 0.9298    \n",
      "Epoch 36/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1589 - acc: 0.9312    \n",
      "Epoch 37/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.1560 - acc: 0.9312    \n",
      "Epoch 38/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1513 - acc: 0.9343    \n",
      "Epoch 39/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.1505 - acc: 0.9348    \n",
      "Epoch 40/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1502 - acc: 0.9327    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124fc1cd0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "try:\n",
    "    model = load_model(\"cnn_nlp_5.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((50,maxdim/50,1), input_shape=(maxdim,)))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_nlp_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4160/4215 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "robotics\n"
     ]
    }
   ],
   "source": [
    "print y_pred[3].argmax()\n",
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    r = y.argmax()\n",
    "    if r ==0:\n",
    "        _y_pred.append('biology')\n",
    "    if r ==1:\n",
    "        _y_pred.append('cooking')\n",
    "    if r ==2:\n",
    "        _y_pred.append('robotics')\n",
    "print _y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765472738448\n"
     ]
    }
   ],
   "source": [
    "fs1_7 = f1_score(np.array(y_test), _y_pred, average='macro') \n",
    "print fs1_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part of the capstone project I have investigated three different approches to transform input text into valuable inputs for machine learning algorithms: Bag-of-words, in which single words are taken, turned into integers and paired with the number of occurencies they have in each single sentence; 2-grams, in which the same thing is done for sequences of 2 words occurring in the same sentence; words vectors, in which any word is turned into a vector of floating values calculated trhough a previous automatic elebaboration of a corpus so that semantically similar words show similar vectors.\n",
    "\n",
    "I have applied Naive Bayes and Random Forest for each Input model in order to see what combination performed better in classifing cooking, robotics and biology questions.\n",
    "\n",
    "It turned out the best solution is Nayve Bayes trained on bi-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Input Model              ML Model    Result\n",
      "0  Bag of Words           Naive Bayes  0.887764\n",
      "1  Bag of Words         Random Forest  0.877510\n",
      "2       2_GRAMS           Naive Bayes  0.896845\n",
      "3       2_GRAMS         Random Forest  0.878467\n",
      "4   WordVectors           Naive Bayes  0.149552\n",
      "5   WordVectors         Random Forest  0.707806\n",
      "6   WordVectors  Conv. Neural Network  0.765473\n"
     ]
    }
   ],
   "source": [
    "result = [['Bag of Words','Naive Bayes',fs1_1],['Bag of Words','Random Forest',fs1_2],\n",
    "          ['2_GRAMS','Naive Bayes',fs1_3],['2_GRAMS','Random Forest',fs1_4],\n",
    "          ['WordVectors','Naive Bayes',fs1_5],['WordVectors','Random Forest',fs1_6],\n",
    "          ['WordVectors','Conv. Neural Network',fs1_7]]\n",
    "result = pd.DataFrame(result,columns=[\"Input Model\",\"ML Model\",\"Result\"])\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try the best model on my own questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model succeds in classifying made up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_topic(q):\n",
    "    q = removePunctuation(q)\n",
    "    q = removeStopwords(q)\n",
    "    q =  ang_title_vectorizer.transform([q])\n",
    "    q = q.toarray()\n",
    "    answer = gnb3.predict(q)\n",
    "    return answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooking\n",
      "biology\n",
      "robotics\n"
     ]
    }
   ],
   "source": [
    "print question_topic('at what temperature should I bake bread?')\n",
    "print question_topic('how high can a frog jump?')\n",
    "print question_topic('how many cameras do I need to create a 3d image?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Problem: Tagging Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we are going to focus on questions of a single topic and try to create a model capable of assigning tags to unknown questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771,)\n"
     ]
    }
   ],
   "source": [
    "robotics_questions = dataframes['robotics']['title']\n",
    "robotics_questions.head()\n",
    "print robotics_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robotics_tags = dataframes['robotics']['tags']\n",
    "rtags = [ti for ta in dataframes[\"robotics\"].tags for ti in ta.split() ]\n",
    "rseries = pd.Series(rtags)\n",
    "counter = Counter(rseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor']\n",
      "[306, 295, 282, 255, 239]\n",
      "239\n",
      "4613\n"
     ]
    }
   ],
   "source": [
    "counter = counter.most_common()\n",
    "maxcount = 50\n",
    "keys = [c[0] for c in counter][:maxcount]\n",
    "counts = [c[1] for c in counter][:maxcount]\n",
    "\n",
    "print keys[:5]\n",
    "print counts[:5]\n",
    "print counts[4]\n",
    "\n",
    "count = 0\n",
    "for c in counts:\n",
    "    count=count+c\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc_tags_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "rc_tags = rc_tags_vectorizer.fit_transform(r_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple benchmark model I am going to extract nouns and gerunds from questions and use them as possible tags. We rely on the pos_tag function (which means 'parts of speech tagging') of the nltk library to extract Nouns and Gerunds and see how this straightforward approach performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_titles = []\n",
    "for i,title in enumerate(r_titles):\n",
    "    pos = []\n",
    "    pt_titl = nltk.pos_tag(word_tokenize(title))\n",
    "    for pt in pt_titl:\n",
    "        #print(pt)\n",
    "        if pt[1]=='NN':\n",
    "            pos.append(pt[0])\n",
    "            #pos.append(pt[0]+'s')\n",
    "        if pt[1]=='NNS':\n",
    "            #pos.append(pt[0])\n",
    "            pos.append(pt[0][:-1])\n",
    "        if pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS':\n",
    "            pos.append(pt[0])\n",
    "    nn_titles.append(\" \".join(pos))\n",
    "nn_titles = [n.split() for n in nn_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following example shows this approach is very simple but can provide interesting results we are now going to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n",
      "['soccer', 'control']\n"
     ]
    }
   ],
   "source": [
    "print nn_titles[0]\n",
    "print r_tags[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec_tags = []\n",
    "for nl in nn_titles:\n",
    "    vt = [0]*rc_tags.shape[1]\n",
    "    for n in nl:\n",
    "        if n in rc_tags_vectorizer.vocabulary_:\n",
    "            vt[rc_tags_vectorizer.vocabulary_.get(n)]=1\n",
    "    vec_tags.append(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(array([123]),)\n",
      "(array([ 10, 123, 164]),)\n",
      "---\n",
      "(array([193]),)\n",
      "(array([148, 193]),)\n",
      "---\n",
      "(array([192]),)\n",
      "(array([122, 192]),)\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()\n",
    "idx = 5\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()\n",
    "idx = 9\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an average of 0.6 for the f1 score metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608191533899\n"
     ]
    }
   ],
   "source": [
    "rc_tags_array = rc_tags.toarray()\n",
    "_score = 0\n",
    "for i,el in enumerate(rc_tags_array):\n",
    "    _score+= f1_score(el,vec_tags[i], average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to do something more sophisticated. We have seen word of vectors performed poorly with CNN for the first classification problem. I'd like now to create a CNN capable of tagging questions better that our NNs based approach (f1_score > 0.6) through word of vectors and I think an improvement could com from creating word vectors from titles' Nouns and Verbs only (avoiding any other POS TAG). \n",
    "\n",
    "Let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_Xe = []\n",
    "for title in nn_titles:\n",
    "    sentence = []\n",
    "    for word in title:\n",
    "        if word in w2v:\n",
    "            wv = w2v[word]\n",
    "            sentence.append(wv)\n",
    "    words = [w for s in sentence for w in s]\n",
    "    a_Xe.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "maxdim = 0\n",
    "for s in a_Xe:\n",
    "    if len(s)>maxdim:\n",
    "        maxdim = len(s)\n",
    "print maxdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for sent in a_Xe:\n",
    "    padd = [0 for _ in range (maxdim - len(sent))]\n",
    "    padd = np.asarray(padd)\n",
    "    paddedsent = np.concatenate((sent,padd),axis=0)\n",
    "    sentences.append(paddedsent)\n",
    "a_Xe = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_Y.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(a_Xe, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 230)\n",
      "(1856, 600)\n"
     ]
    }
   ],
   "source": [
    "print yc_train.shape\n",
    "print np.array(Xc_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5415 - acc: 0.5474     \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5358 - acc: 0.5544     \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5310 - acc: 0.5453     \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5200 - acc: 0.5528     \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5234 - acc: 0.5673     \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5075 - acc: 0.5544     \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5049 - acc: 0.5673     \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5017 - acc: 0.5463     \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.4998 - acc: 0.5506     \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.4901 - acc: 0.5388     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acaf5ad0>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "try:\n",
    "    model = load_model(\"cnn_tags_2.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((maxdim/50,50,1), input_shape=(maxdim,)))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(230, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_tags_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWord(_idx):\n",
    "    for word,idx in r_tag_vectorizer.vocabulary_.iteritems():\n",
    "        if idx == _idx:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.1:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.195349315056\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained the CNN for 40 epochs and the final average f1_score result is about 0.2. I will try with a bi-grams input model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trying with bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r3g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_3g = r3g_title_vectorizer.fit_transform(r_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_Y.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 97s - loss: 2.3694 - acc: 0.5722    \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 95s - loss: 2.3681 - acc: 0.5560    \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 103s - loss: 2.3587 - acc: 0.5717   \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 94s - loss: 2.3556 - acc: 0.5603    \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 91s - loss: 2.3507 - acc: 0.5733    \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 100s - loss: 2.3447 - acc: 0.5663   \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 103s - loss: 2.3483 - acc: 0.5609   \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 95s - loss: 2.3404 - acc: 0.5496    \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 110s - loss: 2.3348 - acc: 0.5684   \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 109s - loss: 2.3337 - acc: 0.5700   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11404ee10>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "maxdim = Xc_train.shape[1]\n",
    "try:\n",
    "    model = load_model(\"cnn_tags_3g_1.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxdim,15,input_length=maxdim))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(230, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_tags_3g_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 9s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.617673068191\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the obtaind result is very similar to previous one meaning the bi-grams input model didn't affect the performance. I will try with random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### back to Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 13343)\n",
      "(1856, 230)\n"
     ]
    }
   ],
   "source": [
    "print Xc_train.shape\n",
    "print yc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(Xc_train, yc_train).predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.590164411529\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the result is about 0.2. Are we dealing with too much tags? Considering how unbalanced the tags are we might have better results if we focused on the most relevant 50 tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying reducing tags and deal with the 50 most relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_top50_tags = []\n",
    "for tags in r_tags:\n",
    "    nr = ''\n",
    "    for tag in word_tokenize(tags):\n",
    "        if tag in keys:\n",
    "            nr+=tag+' '\n",
    "    r_top50_tags.append(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control ', 'control rcservo ', '', ..., 'arduino raspberry-pi ',\n",
       "       'slam ekf ', ''], \n",
       "      dtype='|S76')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(r_top50_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_50tag_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_top50_tags = r_50tag_vectorizer.fit_transform(np.array(r_top50_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 50)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_top50_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor', 'sensors', 'robotic-arm', 'pid', 'localization', 'microcontroller', 'slam', 'ros', 'raspberry-pi', 'irobot-create', 'wheeled-robot', 'design', 'kinematics', 'kalman-filter', 'computer-vision', 'imu', 'motion-planning', 'inverse-kinematics', 'mechanism', 'brushless-motor', 'battery', 'power', 'cameras', 'stepper-motor', 'electronics', 'accelerometer', 'navigation', 'software', 'kinect', 'servos', 'algorithm', 'gyroscope', 'actuator', 'matlab', 'dynamics', 'ekf', 'servomotor', 'sensor-fusion', 'torque', 'mapping', 'esc', 'rcservo', 'industrial-robot', 'gps', 'odometry', 'stereo-vision']\n"
     ]
    }
   ],
   "source": [
    "print keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_top50_tags.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 44s - loss: 1.3097 - acc: 0.5954    \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.3038 - acc: 0.6099    \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 44s - loss: 1.3025 - acc: 0.5900    \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.2994 - acc: 0.6040    \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2986 - acc: 0.5948    \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2936 - acc: 0.6045    \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2913 - acc: 0.5938    \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 39s - loss: 1.2905 - acc: 0.6126    \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.2868 - acc: 0.5997    \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2851 - acc: 0.6002    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cb20e90>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxdim = Xc_train.shape[1]\n",
    "try:\n",
    "    model = load_model(\"cnn_50tags_3g_1.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxdim,15,input_length=maxdim))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_50tags_3g_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "0.640445560283\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top 50 with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50,criterion='entropy')\n",
    "y_pred = clf.fit(Xc_train, yc_train).predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "0.970754098361\n",
      "0.653152914879\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_ascore/len(_y_pred))\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_titles = [\" \".join(n) for n in nn_titles]\n",
    "rnn_title_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "rnn_X = rnn_title_vectorizer.fit_transform(nn_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_top50_tags.toarray()\n",
    "rnn_X_array = rnn_X.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test,idx1,idx2 = train_test_split(rnn_X_array, r_Y_array,range(rnn_X_array.shape[0]), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 50)\n"
     ]
    }
   ],
   "source": [
    "print r_Y_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "gnb_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    gnb_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in gnb_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 915)\n",
      "(915, 50)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66424619993\n",
      "0.96625136612\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a possible hybrid approach: \n",
    "\n",
    "1. we take the list of nouns and gerunds for each questiontitle and contnt and keep only those included in the top 50 tags;\n",
    "2. we use the array of SVMs and GNBs to predict the remaining tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['torque' 'motor']\n"
     ]
    }
   ],
   "source": [
    "#print dataframes['robotics']['content'][0]\n",
    "y_content = [dataframes['robotics']['content'][idx] for idx in idx2]\n",
    "nn_content = []\n",
    "for i,content in enumerate(y_content):\n",
    "    pos = []\n",
    "    pt_cont = nltk.pos_tag(word_tokenize(content))\n",
    "    for pt in pt_cont:\n",
    "        #print(pt)\n",
    "        if pt[0] in keys:\n",
    "            pos.append(pt[0])\n",
    "    pos = pd.Series(pos).unique()\n",
    "    nn_content.append(pos)\n",
    "#nn_content = [n.split() for n in nn_content]\n",
    "nn_content = pd.Series(nn_content)\n",
    "print nn_content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_content[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gear ratio motor\n",
      "['motor']\n"
     ]
    }
   ],
   "source": [
    "extracted = []\n",
    "y_titles = [nn_titles[idx] for idx in idx2]\n",
    "for nt in y_titles:\n",
    "    filtered = []\n",
    "    for n in nt.split():\n",
    "        if n in keys:\n",
    "            filtered.append(n)\n",
    "    extracted.append(filtered)\n",
    "\n",
    "idx = 1\n",
    "print y_titles[idx]\n",
    "print extracted[idx]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted = [\" \".join(e) for e in extracted]\n",
    "c_extracted = [\" \".join(c) for c in nn_content]\n",
    "extr_vec = r_50tag_vectorizer.transform(extracted)\n",
    "c_extr_vec = r_50tag_vectorizer.transform(c_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 31)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 41)\t1\n"
     ]
    }
   ],
   "source": [
    "print c_extr_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "predicted2 = []\n",
    "\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    predicted.append(y_pred)\n",
    "\n",
    "for c2 in gnb_array:\n",
    "    print '*',\n",
    "    y_pred = c2.predict(Xc_test)\n",
    "    predicted2.append(y_pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "predictions = []\n",
    "for idx,el in enumerate(predicted):\n",
    "    pred = [x for x in el.nonzero()[0] if x in predicted2[idx].nonzero()[0]]\n",
    "    predictions.append(pred)\n",
    "\n",
    "    pred_array = []\n",
    "for qi in range(yc_test.shape[0]):\n",
    "    tags = [0]*yc_test.shape[1]\n",
    "    pred_array.append(tags)\n",
    "pred_array = np.array(pred_array)\n",
    "\n",
    "for tag,pred in enumerate(predictions):\n",
    "    for p in pred:\n",
    "        pred_array[pred,tag]=1\n",
    "\n",
    "ext_array = extr_vec.toarray()\n",
    "c_ext_array = c_extr_vec.toarray()\n",
    "print len(ext_array)\n",
    "for idx,e in enumerate(ext_array):\n",
    "    pred_array[idx] = pred_array[idx]|e\n",
    "for idx,c in enumerate(c_ext_array):\n",
    "    pred_array[idx] = pred_array[idx]|c\n",
    "    \n",
    "print pred_array[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691286696385\n",
      "0.956765027322\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(pred_array):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(pred_array))\n",
    "print(_ascore/len(pred_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this hybrid approach we have manged to score 0.23 of F1 still from the 0.3 objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_tags.head()\n",
    "ncounter = Counter(rseries)\n",
    "ncounter = ncounter.most_common()\n",
    "maxcount = 100\n",
    "nkeys = [c[0] for c in ncounter][:maxcount]\n",
    "ncounts = [c[1] for c in ncounter][:maxcount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_top_tags = []\n",
    "for tags in r_tags:\n",
    "    nr = ''\n",
    "    for tag in word_tokenize(tags):\n",
    "        if tag in nkeys:\n",
    "            nr+=tag+' '\n",
    "    r_top_tags.append(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print np.array(nkeys).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r2g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_2g = r2g_title_vectorizer.fit_transform(r_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print r_X_2g.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "r_top_tag_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_top_tags = r_top_tag_vectorizer.fit_transform(np.array(r_top_tags))\n",
    "\n",
    "r_y_array = r_top_tags.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X_2g.toarray(), r_y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 915)\n",
      "(915, 98)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659831901215\n",
      "0.9818779971\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with Title and Content POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n"
     ]
    }
   ],
   "source": [
    "nn_titles = []\n",
    "for i,title in enumerate(r_titles):\n",
    "    pos = []\n",
    "    pt_titl = nltk.pos_tag(word_tokenize(title))\n",
    "    for pt in pt_titl:\n",
    "        #print(pt)\n",
    "        if pt[1]=='NN':\n",
    "            pos.append(pt[0])\n",
    "            #pos.append(pt[0]+'s')\n",
    "        if pt[1]=='NNS':\n",
    "            #pos.append(pt[0])\n",
    "            pos.append(pt[0][:-1])\n",
    "        if pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS':\n",
    "            pos.append(pt[0])\n",
    "    nn_titles.append(\" \".join(pos))\n",
    "nn_titles = [n.split() for n in nn_titles]\n",
    "print nn_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wheel', 'pid', 'motor', 'servos', 'software', 'movement', 'pwm']\n"
     ]
    }
   ],
   "source": [
    "#print dataframes['robotics']['content'][0]\n",
    "contents = dataframes['robotics']['content']\n",
    "nn_content = []\n",
    "for i,content in enumerate(contents):\n",
    "    pos = []\n",
    "    pt_cont = nltk.pos_tag(word_tokenize(content))\n",
    "    for pt in pt_cont:\n",
    "        #print(pt)\n",
    "        tmp = pt[0]\n",
    "        if pt[1]=='NNS':\n",
    "            tmp =  pt[0][:-1]\n",
    "        if tmp in nkeys:\n",
    "            pos.append(tmp)\n",
    "    \n",
    "    pos = pd.Series(pos).unique()\n",
    "    nn_content.append(\" \".join(pos))\n",
    "nn_contents = [n.split() for n in nn_content]\n",
    "print nn_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right approach write spin controller soccer robot\n",
      "p imagine programming 3 wheel soccer robot type controller would use spinning p pid p p goal controller make robot stand defined angle 0 degree turn back rotated hand robot p p use stepper motors robot servos need implement software p p written sample p type controller already movement fairly good would like make better possible code follows p pre code void spinspeed int devidedvalue int addedvalue int correction degree lt correction amp amp degree gt correction motorspeed 0 else degree gt 0 motorspeed degree devidedvalue addedvalue else motorspeed degree devidedvalue addedvalue code pre p code correction code range robot movement code degree code number 127 128 returned compass code motorspeed code number 0 255 applied pwm p\n",
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n",
      "['wheel', 'pid', 'motor', 'servos', 'software', 'movement', 'pwm']\n"
     ]
    }
   ],
   "source": [
    "print dataframes['robotics']['title'][0]\n",
    "print dataframes['robotics']['content'][0]\n",
    "print nn_titles[0]\n",
    "print nn_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_contents = [\" \".join(c) for c in nn_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_titles = [\" \".join(c) for c in nn_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approach spin controller soccer robot\n",
      "wheel pid motor servos software movement pwm\n",
      "approach spin controller soccer robotwheel pid motor servos software movement pwm\n"
     ]
    }
   ],
   "source": [
    "print nn_titles[0]\n",
    "print nn_contents[0]\n",
    "nn_tandc = []\n",
    "for idx,t in enumerate(nn_titles):\n",
    "    tmp = t+nn_contents[idx]\n",
    "    nn_tandc.append(tmp)\n",
    "print nn_tandc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_content_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_X = r_content_vectorizer.fit_transform(nn_tandc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X.toarray(), r_y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 915)\n",
      "(915, 98)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61200735316\n",
      "0.978275900524\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying all Tags with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r2g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_2g = r2g_title_vectorizer.fit_transform(r_titles)\n",
    "r_X_2t_array = r_X_2g.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "r_Y_array = r_Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X_2g.toarray(), r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.SVC()\n",
    "    try:\n",
    "        clf.fit(Xc_train, svm_y[t])\n",
    "        svm_array.append(clf)\n",
    "    except:\n",
    "        svm_array.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    if cl is not None:\n",
    "        y_pred = cl.predict(Xc_test)\n",
    "    else:\n",
    "        y_pred = [0]*Xc_test.shape[0]\n",
    "    out1.append(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 915)\n",
      "(915, 230)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.497963902119\n",
      "0.989736279401\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAFkCAYAAACn/timAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d614850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_tags_histo = [len(ttt.split()) for ttt in r_tags]\n",
    "plt.hist(r_tags_histo, bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 915)\n",
      "(915, 230)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    for idx,v in enumerate(vec):\n",
    "        maxtags = 2\n",
    "        if v==1:\n",
    "            maxtags = maxtags-1\n",
    "            if maxtags ==0:\n",
    "                v=0\n",
    "        vec[idx]=v\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.497963902119\n",
      "0.989736279401\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
