{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Questions Automatic Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Capstone Project of my Udacity Machine Learning Nano Degree.\n",
    "\n",
    "In this capstone project I will focus on one specific kind of problem among the many open problems in NLP: Text Classification. The task is to state what is the topic, among several availables, of a content expressed in natural language. To this end I will rely on the questions shared by Stack Exchange , take three classes of questions (i.e. cooking, robotics, biology) and try to create a model capable of stating to what of these three classes an unknown question belongs. After that I will try to create a model that for the questions of a given topic tries to predict what are the tags that best describe it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    \"cooking\": pd.read_csv(\"cooking.csv\"),\n",
    "    \"biology\": pd.read_csv(\"biology.csv\"),\n",
    "    \"robotics\": pd.read_csv(\"robotics.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes['cooking']['class'] = 'cooking'\n",
    "dataframes['biology']['class'] = 'biology'\n",
    "dataframes['robotics']['class'] = 'robotics'\n",
    "\n",
    "allquestions = pd.concat([dataframes['cooking'][:5000],dataframes['robotics'],dataframes['biology'][:5000]],\n",
    "                        ignore_index=True)\n",
    "#allquestions = allquestions.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                         2\n",
      "title                    How should I cook bacon in an oven?\n",
      "content    <p>I've heard of people cooking bacon in an ov...\n",
      "tags                                 oven cooking-time bacon\n",
      "class                                                cooking\n",
      "Name: 1, dtype: object\n",
      "id                                                         2\n",
      "title      How can I modify a low cost hobby servo to run...\n",
      "content    <p>I've got some hobby servos (<a href=\"http:/...\n",
      "tags                                         control rcservo\n",
      "class                                               robotics\n",
      "Name: 1, dtype: object\n",
      "id                                                         2\n",
      "title      How is RNAse contamination in RNA based experi...\n",
      "content    <p>Does anyone have any suggestions to prevent...\n",
      "tags                                        rna biochemistry\n",
      "class                                                biology\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].iloc[1])\n",
    "print(dataframes[\"robotics\"].iloc[1])\n",
    "print(dataframes[\"biology\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15404, 5)\n",
      "['baking', 'food-safety', 'substitutions', 'equipment', 'bread']\n",
      "[1444, 1211, 920, 816, 687]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBESOAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10415dcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].shape)\n",
    "ctags = [ti for ta in dataframes[\"cooking\"].tags for ti in ta.split() ]\n",
    "cseries = pd.Series(ctags)\n",
    "cus = cseries.unique()\n",
    "counter = Counter(cseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "print(cus.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 5)\n",
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor']\n",
      "[306, 295, 282, 255, 239]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGHCAYAAACNjTnqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d358850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"robotics\"].shape)\n",
    "rtags = [ti for ta in dataframes[\"robotics\"].tags for ti in ta.split() ]\n",
    "rseries = pd.Series(rtags)\n",
    "counter = Counter(rseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "rdf = pd.DataFrame(counter)\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.ylabel('number of questions')\n",
    "plt.xlabel('50 most frequent Tags')\n",
    "plt.title('Top 50 Tags')\n",
    "plt.show()\n",
    "rus = rseries.unique()\n",
    "print(rus.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13196, 5)\n",
      "['human-biology', 'genetics', 'evolution', 'biochemistry', 'molecular-biology']\n",
      "[1448, 1229, 1159, 984, 863]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d3097d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"biology\"].shape)\n",
    "btags = [ti for ta in dataframes[\"biology\"].tags for ti in ta.split() ]\n",
    "bseries = pd.Series(btags)\n",
    "counter = Counter(bseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "bus = bseries.unique()\n",
    "print(bus.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is transforming the input text into something that is machine readble which basically means numbers. \n",
    "We have to drop all the elemnts that do not provide relevant information. Since questions titles may contains html tags and uris we have to remove them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?]))'\n",
    "def stripTagsAndUris(x):\n",
    "    if x:\n",
    "        soup = BeautifulSoup(x, \"html.parser\")\n",
    "        if soup.code:\n",
    "            soup.code.decompose()\n",
    "        text =  soup.get_text()\n",
    "        return re.sub(uri_re, \"\", text)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removePunctuation(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "def removeStopwords(x):\n",
    "    filtered_words = [word for word in x.split() if word not in stops]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textprep(_df):\n",
    "    for df in _df.values():\n",
    "        df[\"title\"] = df[\"title\"].map(removePunctuation)\n",
    "        df[\"title\"] = df[\"title\"].map(removeStopwords)\n",
    "        df[\"content\"] = df[\"content\"].map(removePunctuation)\n",
    "        df[\"content\"] = df[\"content\"].map(removeStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textprep(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                         2\n",
      "title                                        cook bacon oven\n",
      "content    p heard people cooking bacon oven laying strip...\n",
      "tags                                 oven cooking-time bacon\n",
      "class                                                cooking\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest approach is the so called Bag-of-words model where the text is represented by the set of words contained in it, loosing their order and thus disregarding the grammar or the syntax. Each word is paired with an integer representing the occurrencies of that word in the represented text. One of the weak aspect of this approach is that longer text may present more occurrencies of a given word, with respect to a shorter text, not because of its relevance but just because the text is longer. \n",
    "\n",
    "Since we rely in titles, which are short by construction, I think this aspect will not affect our task.\n",
    "\n",
    "We rely on scikit learn CountVectorizer to transform words into numbers. We use a custom token pattern in order to catch words containing the '-' character like 'cooking-time'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing cooking titles\n",
      "vectorizing robotics titles\n",
      "vectorizing biology titles\n",
      "vectorizing cooking tags\n",
      "vectorizing robotics tags\n",
      "vectorizing biology tags\n",
      "vectorizing all titles\n"
     ]
    }
   ],
   "source": [
    "c_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "c_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "b_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "b_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "\n",
    "a_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "a_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "\n",
    "c_titles = dataframes['cooking']['title']\n",
    "r_titles = dataframes['robotics']['title']\n",
    "b_titles = dataframes['biology']['title']\n",
    "\n",
    "c_tags = dataframes['cooking']['tags']\n",
    "r_tags = dataframes['robotics']['tags']\n",
    "b_tags = dataframes['biology']['tags']\n",
    "\n",
    "a_titles  = allquestions['title']\n",
    "a_classes = allquestions['class']\n",
    "\n",
    "print \"vectorizing cooking titles\"\n",
    "c_X = c_title_vectorizer.fit_transform(c_titles)\n",
    "print \"vectorizing robotics titles\"\n",
    "r_X = r_title_vectorizer.fit_transform(r_titles)\n",
    "print \"vectorizing biology titles\"\n",
    "b_X = b_title_vectorizer.fit_transform(b_titles)\n",
    "\n",
    "print \"vectorizing cooking tags\"\n",
    "c_Y = c_tag_vectorizer.fit_transform(c_tags)\n",
    "print \"vectorizing robotics tags\"\n",
    "r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "print \"vectorizing biology tags\"\n",
    "b_Y = b_tag_vectorizer.fit_transform(b_tags)\n",
    "\n",
    "print \"vectorizing all titles\"\n",
    "a_X = a_title_vectorizer.fit_transform(a_titles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2573)\t1\n",
      "  (0, 1974)\t1\n",
      "  (0, 1990)\t1\n",
      "  (0, 1937)\t1\n"
     ]
    }
   ],
   "source": [
    "print(a_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of single words like the bag-of-words fail capture phrases and expressions of multiple words. A more valuable approch is to consider single words along with sequences of adjcent words called n-grams. In this project we use bi-grams as a possible input model. Fortunately the CountVectorizer class can be configured to extract any range of ngram with the ngram_range(min,max) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing all titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "ang_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing all titles with 2-grams\"\n",
    "a_X_2g = ang_title_vectorizer.fit_transform(a_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8358)\t1\n",
      "  (0, 8419)\t1\n",
      "  (0, 8143)\t1\n",
      "  (0, 11082)\t1\n",
      "  (0, 8355)\t1\n",
      "  (0, 8405)\t1\n",
      "  (0, 8141)\t1\n"
     ]
    }
   ],
   "source": [
    "print(a_X_2g[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated approach is to rely on vector space representations of words. Basically the idea is to exploit a previously created lookup table in which, for each word of our vocabulary, a vector of float valus corresponds. Their interesting property is that two words with similar meaning have similar vectors. These vectors are generally created automatically with a separated machine learning approach on big corpus of texts. \n",
    "In this project we rely on an already exsiting vector space called Glove.\n",
    "\n",
    "https://nlp.stanford.edu/pubs/glove.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = {}\n",
    "with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here follows an example of what the pre-trained data can be used to retrieve vectors of values for each single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68163   1.1578   -0.47827   0.41421  -0.53186   0.63827  -0.90381\n",
      "  0.50795   0.057398 -0.29163   1.1411   -0.079702  0.19951   1.1925\n",
      "  0.52281   0.78633   0.78555   0.32624  -1.5504   -1.0191    0.35532\n",
      " -0.38875   0.92789   0.24325  -0.43162  -0.54939  -0.52209   1.0721\n",
      "  0.99558  -0.38605   2.2673    0.41067  -0.08973   0.29741  -0.18678\n",
      "  0.44329  -0.42243   0.80558   1.1306    0.14038  -0.089723  0.1341\n",
      "  0.47948  -0.12774   0.024234  0.051782  0.44778  -0.47974  -0.62491\n",
      " -0.90005 ]\n"
     ]
    }
   ],
   "source": [
    "keys= w2v.keys()\n",
    "print (w2v['ice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_Xe = []\n",
    "for title in a_titles:\n",
    "    sentence = []\n",
    "    for word in title.split():\n",
    "        if word in w2v:\n",
    "            wv = w2v[word]\n",
    "            sentence.append(wv)\n",
    "    words = [w for s in sentence for w in s]\n",
    "    a_Xe.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "maxdim = 0\n",
    "for s in a_Xe:\n",
    "    if len(s)>maxdim:\n",
    "        maxdim = len(s)\n",
    "print maxdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for sent in a_Xe:\n",
    "    padd = [0 for _ in range (maxdim - len(sent))]\n",
    "    padd = np.asarray(padd)\n",
    "    paddedsent = np.concatenate((sent,padd),axis=0)\n",
    "    sentences.append(paddedsent)\n",
    "a_Xe = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35145   -0.24155    0.0054776 ...,  0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "print a_Xe[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Problem: Questions Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first problem I will try to create a model capable of stating, given an unknown question, to what class it belongs. I will try Naive Bayes and Random Forest on input data modeled through Bag of Words, n-grams (with n = 2) and word vectors (Glove). In the third case I will also try to train a Convolutional Neural Network. \n",
    "\n",
    "I will compare the obtained 7 models through the F1score metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12771, 12661)\n"
     ]
    }
   ],
   "source": [
    "print a_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a_X.toarray(), a_classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology\n",
      "biology\n"
     ]
    }
   ],
   "source": [
    "idx = 351\n",
    "print np.array(y_test)[idx]\n",
    "print y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887763885977\n"
     ]
    }
   ],
   "source": [
    "fs1_1 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877509953024\n"
     ]
    }
   ],
   "source": [
    "fs1_2 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12771, 55882)\n",
      "(12771,)\n"
     ]
    }
   ],
   "source": [
    "a_X_2g_array = a_X_2g.toarray()\n",
    "print(a_X_2g_array.shape)\n",
    "print(a_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3g_train, X3g_test, y3g_train, y3g_test = train_test_split(a_X_2g_array, a_classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb3 = GaussianNB()\n",
    "y_pred = gnb3.fit(X3g_train, y3g_train).predict(X3g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896844697847\n"
     ]
    }
   ],
   "source": [
    "fs1_3 = f1_score(np.array(y3g_test), y_pred, average='macro') \n",
    "print fs1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X3g_train, y3g_train).predict(X3g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878467432249\n"
     ]
    }
   ],
   "source": [
    "fs1_4 = f1_score(np.array(y3g_test), y_pred, average='macro') \n",
    "print fs1_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_classes = a_classes.str.get_dummies()\n",
    "#print cat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a_Xe, a_classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(a_Xe, cat_classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.149552249279\n"
     ]
    }
   ],
   "source": [
    "fs1_5 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707805926699\n"
     ]
    }
   ],
   "source": [
    "fs1_6 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3970 - acc: 0.8319    \n",
      "Epoch 2/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3860 - acc: 0.8365    \n",
      "Epoch 3/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3733 - acc: 0.8375    \n",
      "Epoch 4/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3636 - acc: 0.8434    \n",
      "Epoch 5/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3514 - acc: 0.8511    \n",
      "Epoch 6/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3424 - acc: 0.8574    \n",
      "Epoch 7/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3318 - acc: 0.8620    \n",
      "Epoch 8/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3217 - acc: 0.8622    \n",
      "Epoch 9/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3111 - acc: 0.8717    \n",
      "Epoch 10/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3039 - acc: 0.8706    \n",
      "Epoch 11/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2952 - acc: 0.8742    \n",
      "Epoch 12/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2838 - acc: 0.8793    \n",
      "Epoch 13/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2774 - acc: 0.8828    \n",
      "Epoch 14/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2734 - acc: 0.8852    \n",
      "Epoch 15/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2631 - acc: 0.8891    \n",
      "Epoch 16/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.2551 - acc: 0.8928    \n",
      "Epoch 17/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2487 - acc: 0.8946    \n",
      "Epoch 18/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2442 - acc: 0.8977    \n",
      "Epoch 19/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2338 - acc: 0.9017    \n",
      "Epoch 20/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.2270 - acc: 0.9038    \n",
      "Epoch 21/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2215 - acc: 0.9050    \n",
      "Epoch 22/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.2186 - acc: 0.9047    \n",
      "Epoch 23/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2123 - acc: 0.9090    \n",
      "Epoch 24/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.2046 - acc: 0.9113    \n",
      "Epoch 25/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.1995 - acc: 0.9140    \n",
      "Epoch 26/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.1968 - acc: 0.9154    \n",
      "Epoch 27/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.1903 - acc: 0.9156    \n",
      "Epoch 28/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.1902 - acc: 0.9182    \n",
      "Epoch 29/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1854 - acc: 0.9184    \n",
      "Epoch 30/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1814 - acc: 0.9213    \n",
      "Epoch 31/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1754 - acc: 0.9237    \n",
      "Epoch 32/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1761 - acc: 0.9247    \n",
      "Epoch 33/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1683 - acc: 0.9279    \n",
      "Epoch 34/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1672 - acc: 0.9264    \n",
      "Epoch 35/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1619 - acc: 0.9298    \n",
      "Epoch 36/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1589 - acc: 0.9312    \n",
      "Epoch 37/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.1560 - acc: 0.9312    \n",
      "Epoch 38/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1513 - acc: 0.9343    \n",
      "Epoch 39/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.1505 - acc: 0.9348    \n",
      "Epoch 40/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1502 - acc: 0.9327    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124fc1cd0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "try:\n",
    "    model = load_model(\"cnn_nlp_5.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((50,maxdim/50,1), input_shape=(maxdim,)))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_nlp_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4160/4215 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "robotics\n"
     ]
    }
   ],
   "source": [
    "print y_pred[3].argmax()\n",
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    r = y.argmax()\n",
    "    if r ==0:\n",
    "        _y_pred.append('biology')\n",
    "    if r ==1:\n",
    "        _y_pred.append('cooking')\n",
    "    if r ==2:\n",
    "        _y_pred.append('robotics')\n",
    "print _y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765472738448\n"
     ]
    }
   ],
   "source": [
    "fs1_7 = f1_score(np.array(y_test), _y_pred, average='macro') \n",
    "print fs1_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part of the capstone project I have investigated three different approches to transform input text into valuable inputs for machine learning algorithms: Bag-of-words, in which single words are taken, turned into integers and paired with the number of occurencies they have in each single sentence; 2-grams, in which the same thing is done for sequences of 2 words occurring in the same sentence; words vectors, in which any word is turned into a vector of floating values calculated trhough a previous automatic elebaboration of a corpus so that semantically similar words show similar vectors.\n",
    "\n",
    "I have applied Naive Bayes and Random Forest for each Input model in order to see what combination performed better in classifing cooking, robotics and biology questions.\n",
    "\n",
    "It turned out the best solution is Nayve Bayes trained on bi-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Input Model              ML Model    Result\n",
      "0  Bag of Words           Naive Bayes  0.887764\n",
      "1  Bag of Words         Random Forest  0.877510\n",
      "2       2_GRAMS           Naive Bayes  0.896845\n",
      "3       2_GRAMS         Random Forest  0.878467\n",
      "4   WordVectors           Naive Bayes  0.149552\n",
      "5   WordVectors         Random Forest  0.707806\n",
      "6   WordVectors  Conv. Neural Network  0.765473\n"
     ]
    }
   ],
   "source": [
    "result = [['Bag of Words','Naive Bayes',fs1_1],['Bag of Words','Random Forest',fs1_2],\n",
    "          ['2_GRAMS','Naive Bayes',fs1_3],['2_GRAMS','Random Forest',fs1_4],\n",
    "          ['WordVectors','Naive Bayes',fs1_5],['WordVectors','Random Forest',fs1_6],\n",
    "          ['WordVectors','Conv. Neural Network',fs1_7]]\n",
    "result = pd.DataFrame(result,columns=[\"Input Model\",\"ML Model\",\"Result\"])\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try the best model on my own questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model succeds in classifying made up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_topic(q):\n",
    "    q = removePunctuation(q)\n",
    "    q = removeStopwords(q)\n",
    "    q =  ang_title_vectorizer.transform([q])\n",
    "    q = q.toarray()\n",
    "    answer = gnb3.predict(q)\n",
    "    return answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooking\n",
      "biology\n",
      "robotics\n"
     ]
    }
   ],
   "source": [
    "print question_topic('at what temperature should I bake bread?')\n",
    "print question_topic('how high can a frog jump?')\n",
    "print question_topic('how many cameras do I need to create a 3d image?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Problem: Tagging Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we are going to focus on questions of a single topic and try to create a model capable of assigning tags to unknown questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771,)\n"
     ]
    }
   ],
   "source": [
    "robotics_questions = dataframes['robotics']['title']\n",
    "robotics_questions.head()\n",
    "print robotics_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robotics_tags = dataframes['robotics']['tags']\n",
    "rtags = [ti for ta in dataframes[\"robotics\"].tags for ti in ta.split() ]\n",
    "rseries = pd.Series(rtags)\n",
    "counter = Counter(rseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor']\n",
      "[306, 295, 282, 255, 239]\n",
      "239\n",
      "4613\n"
     ]
    }
   ],
   "source": [
    "counter = counter.most_common()\n",
    "maxcount = 50\n",
    "keys = [c[0] for c in counter][:maxcount]\n",
    "counts = [c[1] for c in counter][:maxcount]\n",
    "\n",
    "print keys[:5]\n",
    "print counts[:5]\n",
    "print counts[4]\n",
    "\n",
    "count = 0\n",
    "for c in counts:\n",
    "    count=count+c\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc_tags_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "rc_tags = rc_tags_vectorizer.fit_transform(r_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple benchmark model I am going to extract nouns and gerunds from questions and use them as possible tags. We rely on the pos_tag function (which means 'parts of speech tagging') of the nltk library to extract Nouns and Gerunds and see how this straightforward approach performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_titles = []\n",
    "for i,title in enumerate(r_titles):\n",
    "    pos = []\n",
    "    pt_titl = nltk.pos_tag(word_tokenize(title))\n",
    "    for pt in pt_titl:\n",
    "        #print(pt)\n",
    "        if pt[1]=='NN':\n",
    "            pos.append(pt[0])\n",
    "            #pos.append(pt[0]+'s')\n",
    "        if pt[1]=='NNS':\n",
    "            #pos.append(pt[0])\n",
    "            pos.append(pt[0][:-1])\n",
    "        if pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS':\n",
    "            pos.append(pt[0])\n",
    "    nn_titles.append(\" \".join(pos))\n",
    "nn_titles = [n.split() for n in nn_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following example shows this approach is very simple but can provide interesting results we are now going to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n",
      "['soccer', 'control']\n"
     ]
    }
   ],
   "source": [
    "print nn_titles[0]\n",
    "print r_tags[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec_tags = []\n",
    "for nl in nn_titles:\n",
    "    vt = [0]*rc_tags.shape[1]\n",
    "    for n in nl:\n",
    "        if n in rc_tags_vectorizer.vocabulary_:\n",
    "            vt[rc_tags_vectorizer.vocabulary_.get(n)]=1\n",
    "    vec_tags.append(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(array([123]),)\n",
      "(array([ 10, 123, 164]),)\n",
      "---\n",
      "(array([193]),)\n",
      "(array([148, 193]),)\n",
      "---\n",
      "(array([192]),)\n",
      "(array([122, 192]),)\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()\n",
    "idx = 5\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()\n",
    "idx = 9\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an average of 0.6 for the f1 score metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608191533899\n"
     ]
    }
   ],
   "source": [
    "rc_tags_array = rc_tags.toarray()\n",
    "_score = 0\n",
    "for i,el in enumerate(rc_tags_array):\n",
    "    _score+= f1_score(el,vec_tags[i], average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to do something more sophisticated. We have seen word of vectors performed poorly with CNN for the first classification problem. I'd like now to create a CNN capable of tagging questions better that our NNs based approach (f1_score > 0.6) through word of vectors and I think an improvement could com from creating word vectors from titles' Nouns and Verbs only (avoiding any other POS TAG). \n",
    "\n",
    "Let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_Xe = []\n",
    "for title in nn_titles:\n",
    "    sentence = []\n",
    "    for word in title:\n",
    "        if word in w2v:\n",
    "            wv = w2v[word]\n",
    "            sentence.append(wv)\n",
    "    words = [w for s in sentence for w in s]\n",
    "    a_Xe.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "maxdim = 0\n",
    "for s in a_Xe:\n",
    "    if len(s)>maxdim:\n",
    "        maxdim = len(s)\n",
    "print maxdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for sent in a_Xe:\n",
    "    padd = [0 for _ in range (maxdim - len(sent))]\n",
    "    padd = np.asarray(padd)\n",
    "    paddedsent = np.concatenate((sent,padd),axis=0)\n",
    "    sentences.append(paddedsent)\n",
    "a_Xe = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_Y.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(a_Xe, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 230)\n",
      "(1856, 600)\n"
     ]
    }
   ],
   "source": [
    "print yc_train.shape\n",
    "print np.array(Xc_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5415 - acc: 0.5474     \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5358 - acc: 0.5544     \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5310 - acc: 0.5453     \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5200 - acc: 0.5528     \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5234 - acc: 0.5673     \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5075 - acc: 0.5544     \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5049 - acc: 0.5673     \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5017 - acc: 0.5463     \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.4998 - acc: 0.5506     \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.4901 - acc: 0.5388     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acaf5ad0>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "try:\n",
    "    model = load_model(\"cnn_tags_2.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((maxdim/50,50,1), input_shape=(maxdim,)))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(230, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_tags_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"cnn_tags_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896/915 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWord(_idx):\n",
    "    for word,idx in r_tag_vectorizer.vocabulary_.iteritems():\n",
    "        if idx == _idx:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.1:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.591598854668\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained the CNN for 40 epochs and the final average f1_score result is about 0.59. I will try with a bi-grams input model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trying with bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r3g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_3g = r3g_title_vectorizer.fit_transform(r_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_Y.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 97s - loss: 2.3694 - acc: 0.5722    \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 95s - loss: 2.3681 - acc: 0.5560    \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 103s - loss: 2.3587 - acc: 0.5717   \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 94s - loss: 2.3556 - acc: 0.5603    \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 91s - loss: 2.3507 - acc: 0.5733    \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 100s - loss: 2.3447 - acc: 0.5663   \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 103s - loss: 2.3483 - acc: 0.5609   \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 95s - loss: 2.3404 - acc: 0.5496    \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 110s - loss: 2.3348 - acc: 0.5684   \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 109s - loss: 2.3337 - acc: 0.5700   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11404ee10>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "maxdim = Xc_train.shape[1]\n",
    "try:\n",
    "    model = load_model(\"cnn_tags_3g_1.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxdim,15,input_length=maxdim))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(230, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_tags_3g_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 9s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.617673068191\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the obtaind result is very similar to previous one meaning the bi-grams input model didn't affect the performance. I will try with random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### back to Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 13343)\n",
      "(1856, 230)\n"
     ]
    }
   ],
   "source": [
    "print Xc_train.shape\n",
    "print yc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(Xc_train, yc_train).predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.590164411529\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the result is about 0.2. Are we dealing with too much tags? Considering how unbalanced the tags are we might have better results if we focused on the most relevant 50 tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying reducing tags and deal with the 50 most relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_top50_tags = []\n",
    "for tags in r_tags:\n",
    "    nr = ''\n",
    "    for tag in word_tokenize(tags):\n",
    "        if tag in keys:\n",
    "            nr+=tag+' '\n",
    "    r_top50_tags.append(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control ', 'control rcservo ', '', ..., 'arduino raspberry-pi ',\n",
       "       'slam ekf ', ''], \n",
       "      dtype='|S76')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(r_top50_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_50tag_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_top50_tags = r_50tag_vectorizer.fit_transform(np.array(r_top50_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_top50_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor', 'sensors', 'robotic-arm', 'pid', 'localization', 'microcontroller', 'slam', 'ros', 'raspberry-pi', 'irobot-create', 'wheeled-robot', 'design', 'kinematics', 'kalman-filter', 'computer-vision', 'imu', 'motion-planning', 'inverse-kinematics', 'mechanism', 'brushless-motor', 'battery', 'power', 'cameras', 'stepper-motor', 'electronics', 'accelerometer', 'navigation', 'software', 'kinect', 'servos', 'algorithm', 'gyroscope', 'actuator', 'matlab', 'dynamics', 'ekf', 'servomotor', 'sensor-fusion', 'torque', 'mapping', 'esc', 'rcservo', 'industrial-robot', 'gps', 'odometry', 'stereo-vision']\n"
     ]
    }
   ],
   "source": [
    "print keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_top50_tags.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 44s - loss: 1.3097 - acc: 0.5954    \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.3038 - acc: 0.6099    \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 44s - loss: 1.3025 - acc: 0.5900    \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.2994 - acc: 0.6040    \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2986 - acc: 0.5948    \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2936 - acc: 0.6045    \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2913 - acc: 0.5938    \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 39s - loss: 1.2905 - acc: 0.6126    \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.2868 - acc: 0.5997    \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.2851 - acc: 0.6002    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12cb20e90>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxdim = Xc_train.shape[1]\n",
    "try:\n",
    "    model = load_model(\"cnn_50tags_3g_1.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxdim,15,input_length=maxdim))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_50tags_3g_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "0.640445560283\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top 50 with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50,criterion='entropy')\n",
    "y_pred = clf.fit(Xc_train, yc_train).predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "0.970754098361\n",
      "0.653152914879\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_ascore/len(_y_pred))\n",
    "print(_score/len(_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_titles = [\" \".join(n) for n in nn_titles]\n",
    "rnn_title_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "rnn_X = rnn_title_vectorizer.fit_transform(nn_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_top50_tags.toarray()\n",
    "rnn_X_array = rnn_X.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test,idx1,idx2 = train_test_split(rnn_X_array, r_Y_array,range(rnn_X_array.shape[0]), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 50)\n"
     ]
    }
   ],
   "source": [
    "print r_Y_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "gnb_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    gnb_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out_svm = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out_svm.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out_nb = []\n",
    "for cl in gnb_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out_nb.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 915)\n",
      "(915, 50)\n"
     ]
    }
   ],
   "source": [
    "out_svm = np.array(out_svm)\n",
    "print out_svm.shape\n",
    "res = []\n",
    "for q in range(out_svm.shape[1]):\n",
    "    vec = [out_svm[t,q] for t in range(out_svm.shape[0])]\n",
    "    res.append(vec)\n",
    "res_svm = np.array(res)\n",
    "print res_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 915)\n",
      "(915, 50)\n"
     ]
    }
   ],
   "source": [
    "out_nb = np.array(out_nb)\n",
    "print out_nb.shape\n",
    "res_nb = []\n",
    "for q in range(out_nb.shape[1]):\n",
    "    vec = [out_nb[t,q] for t in range(out_nb.shape[0])]\n",
    "    res_nb.append(vec)\n",
    "res_nb = np.array(res_nb)\n",
    "print res_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66424619993\n",
      "0.96625136612\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res_svm):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res_svm))\n",
    "print(_ascore/len(res_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562786905339\n",
      "0.885005464481\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res_nb):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res_nb))\n",
    "print(_ascore/len(res_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hybrid approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a possible hybrid approach: \n",
    "\n",
    "1. we take the list of nouns and gerunds for each questiontitle and contnt and keep only those included in the top 50 tags;\n",
    "2. we use the array of SVMs and GNBs to predict the remaining tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter' 'pid' 'sensors']\n"
     ]
    }
   ],
   "source": [
    "#print dataframes['robotics']['content'][0]\n",
    "y_content = [dataframes['robotics']['content'][idx] for idx in idx2]\n",
    "nn_content = []\n",
    "for i,content in enumerate(y_content):\n",
    "    pos = []\n",
    "    pt_cont = nltk.pos_tag(word_tokenize(content))\n",
    "    for pt in pt_cont:\n",
    "        #print(pt)\n",
    "        if pt[0] in keys:\n",
    "            pos.append(pt[0])\n",
    "    pos = pd.Series(pos).unique()\n",
    "    nn_content.append(pos)\n",
    "#nn_content = [n.split() for n in nn_content]\n",
    "nn_content = pd.Series(nn_content)\n",
    "print nn_content[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['quadcopter', 'pid', 'sensors'], dtype=object)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_content[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raspberry pi quadcopter drift crazy\n",
      "['quadcopter']\n"
     ]
    }
   ],
   "source": [
    "extracted = []\n",
    "y_titles = [nn_titles[idx] for idx in idx2]\n",
    "for nt in y_titles:\n",
    "    filtered = []\n",
    "    for n in nt.split():\n",
    "        if n in keys:\n",
    "            filtered.append(n)\n",
    "    extracted.append(filtered)\n",
    "\n",
    "idx = 19\n",
    "print y_titles[idx]\n",
    "print extracted[idx]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted = [\" \".join(e) for e in extracted]\n",
    "c_extracted = [\" \".join(c) for c in nn_content]\n",
    "extr_vec = r_50tag_vectorizer.transform(extracted)\n",
    "c_extr_vec = r_50tag_vectorizer.transform(c_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 31)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 41)\t1\n"
     ]
    }
   ],
   "source": [
    "print c_extr_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "predicted2 = []\n",
    "\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    predicted.append(y_pred)\n",
    "\n",
    "for c2 in gnb_array:\n",
    "    print '*',\n",
    "    y_pred = c2.predict(Xc_test)\n",
    "    predicted2.append(y_pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "predictions = []\n",
    "for idx,el in enumerate(predicted):\n",
    "    pred = [x for x in el.nonzero()[0] if x in predicted2[idx].nonzero()[0]]\n",
    "    predictions.append(pred)\n",
    "\n",
    "    pred_array = []\n",
    "for qi in range(yc_test.shape[0]):\n",
    "    tags = [0]*yc_test.shape[1]\n",
    "    pred_array.append(tags)\n",
    "pred_array = np.array(pred_array)\n",
    "\n",
    "for tag,pred in enumerate(predictions):\n",
    "    for p in pred:\n",
    "        pred_array[pred,tag]=1\n",
    "\n",
    "ext_array = extr_vec.toarray()\n",
    "c_ext_array = c_extr_vec.toarray()\n",
    "print len(ext_array)\n",
    "for idx,e in enumerate(ext_array):\n",
    "    pred_array[idx] = pred_array[idx]|e\n",
    "for idx,c in enumerate(c_ext_array):\n",
    "    pred_array[idx] = pred_array[idx]|c\n",
    "    \n",
    "print pred_array[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691286696385\n",
      "0.956765027322\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(pred_array):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(pred_array))\n",
    "print(_ascore/len(pred_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this hybrid approach we have manged to score 0.69 of F1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uq = []\n",
    "t1 = 'difference between sabertooth motor controller and rc esc?'\n",
    "c1 = 'i am building a rc/robot mower. most of the youtube videos show the sabertooth motor controllers being used to connect the rc receiver to the dc motors. But here in Australia, the sabertooth i need cost about 200 dollars. RC esc sell for about 10 dollars. What is the difference between the esc and the sabertooth and can i use an esc instead?the specs i have on the motor and battery are 12v 10amp normal, 35amp stall. and my rc is a flysky'\n",
    "q={'title':t1,'content':c1}\n",
    "uq.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference between sabertooth motor controller and rc esc?\n"
     ]
    }
   ],
   "source": [
    "print uq[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictTags(title,content):\n",
    "    title  = removePunctuation(title)\n",
    "    title = removeStopwords(title)\n",
    "    content = removePunctuation(content)\n",
    "    content = removeStopwords(content)\n",
    "    nn_titles = []\n",
    "    \n",
    "    pos = []\n",
    "    pt_titl = nltk.pos_tag(word_tokenize(title))\n",
    "    for pt in pt_titl:\n",
    "        #print(pt)\n",
    "        if pt[1]=='NN':\n",
    "            pos.append(pt[0])\n",
    "            #pos.append(pt[0]+'s')\n",
    "        if pt[1]=='NNS':\n",
    "            #pos.append(pt[0])\n",
    "            pos.append(pt[0][:-1])\n",
    "        if pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS':\n",
    "            pos.append(pt[0])\n",
    "    nn_titles.append(\" \".join(pos))\n",
    "    nn_titles = [n.split() for n in nn_titles]\n",
    "    nn_titles = [\" \".join(n) for n in nn_titles]\n",
    "    rnn_X = rnn_title_vectorizer.transform(nn_titles)\n",
    "    print len (rnn_title_vectorizer.vocabulary_)\n",
    "    extracted = []\n",
    "    for nt in nn_titles:\n",
    "        filtered = []\n",
    "        for n in nt.split():\n",
    "            if n in keys:\n",
    "                filtered.append(n)\n",
    "        extracted.append(filtered)\n",
    "        \n",
    "    pt_cont = nltk.pos_tag(word_tokenize(content))\n",
    "    nn_content = []\n",
    "    for pt in pt_cont:\n",
    "        if pt[0] in keys:\n",
    "            pos.append(pt[0])\n",
    "    pos = pd.Series(pos).unique()\n",
    "    nn_content.append(pos)\n",
    "    nn_content = pd.Series(nn_content)  \n",
    "   \n",
    "    extracted = [\" \".join(e) for e in extracted]\n",
    "    c_extracted = [\" \".join(c) for c in nn_content]\n",
    "    extr_vec = r_50tag_vectorizer.transform(extracted)\n",
    "    c_extr_vec = r_50tag_vectorizer.transform(c_extracted)\n",
    "    \n",
    "    predicted = []\n",
    "    predicted2 = []\n",
    "    nx = rnn_X.toarray()\n",
    "    #print nx        \n",
    "    for cl in svm_array:\n",
    "        y_pred = cl.predict(np.array(nx).reshape(1,-1))\n",
    "        predicted.append(y_pred)\n",
    "\n",
    "    for c2 in gnb_array:\n",
    "        y_pred = c2.predict(np.array(nx).reshape(1,-1))\n",
    "        predicted2.append(y_pred)\n",
    "    \n",
    "    print predicted2[30].nonzero()[0]\n",
    "    \n",
    "    predictions = []\n",
    "    for idx,el in enumerate(predicted):\n",
    "        pred = [x for x in el.nonzero()[0] if x in predicted2[idx].nonzero()[0]]\n",
    "        predictions.append(pred)\n",
    "\n",
    "    result =[0] * yc_test.shape[1]\n",
    "    result = np.array(result)\n",
    "\n",
    "    for tag,pred in enumerate(predictions):\n",
    "        for p in pred:\n",
    "            result[pred,tag]=1\n",
    "\n",
    "    ext_array = extr_vec.toarray()\n",
    "    \n",
    "    c_ext_array = c_extr_vec.toarray()\n",
    "    for idx,e in enumerate(ext_array):\n",
    "        result[idx] = pred_array[idx]|e\n",
    "    for idx,c in enumerate(c_ext_array):\n",
    "        result[idx] = pred_array[idx]|c\n",
    "    \n",
    "    print result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n",
      "[0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-2784ea890532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictTags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-197-baf1f103c2bd>\u001b[0m in \u001b[0;36mpredictTags\u001b[0;34m(title, content)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mext_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextr_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "predictTags(t1,c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_tags.head()\n",
    "ncounter = Counter(rseries)\n",
    "ncounter = ncounter.most_common()\n",
    "maxcount = 100\n",
    "nkeys = [c[0] for c in ncounter][:maxcount]\n",
    "ncounts = [c[1] for c in ncounter][:maxcount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_top_tags = []\n",
    "for tags in r_tags:\n",
    "    nr = ''\n",
    "    for tag in word_tokenize(tags):\n",
    "        if tag in nkeys:\n",
    "            nr+=tag+' '\n",
    "    r_top_tags.append(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print np.array(nkeys).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r2g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_2g = r2g_title_vectorizer.fit_transform(r_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print r_X_2g.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "r_top_tag_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_top_tags = r_top_tag_vectorizer.fit_transform(np.array(r_top_tags))\n",
    "\n",
    "r_y_array = r_top_tags.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X_2g.toarray(), r_y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 915)\n",
      "(915, 98)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659831901215\n",
      "0.9818779971\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with Title and Content POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n"
     ]
    }
   ],
   "source": [
    "nn_titles = []\n",
    "for i,title in enumerate(r_titles):\n",
    "    pos = []\n",
    "    pt_titl = nltk.pos_tag(word_tokenize(title))\n",
    "    for pt in pt_titl:\n",
    "        #print(pt)\n",
    "        if pt[1]=='NN':\n",
    "            pos.append(pt[0])\n",
    "            #pos.append(pt[0]+'s')\n",
    "        if pt[1]=='NNS':\n",
    "            #pos.append(pt[0])\n",
    "            pos.append(pt[0][:-1])\n",
    "        if pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS':\n",
    "            pos.append(pt[0])\n",
    "    nn_titles.append(\" \".join(pos))\n",
    "nn_titles = [n.split() for n in nn_titles]\n",
    "print nn_titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wheel', 'pid', 'motor', 'servos', 'software', 'movement', 'pwm']\n"
     ]
    }
   ],
   "source": [
    "#print dataframes['robotics']['content'][0]\n",
    "contents = dataframes['robotics']['content']\n",
    "nn_content = []\n",
    "for i,content in enumerate(contents):\n",
    "    pos = []\n",
    "    pt_cont = nltk.pos_tag(word_tokenize(content))\n",
    "    for pt in pt_cont:\n",
    "        #print(pt)\n",
    "        tmp = pt[0]\n",
    "        if pt[1]=='NNS':\n",
    "            tmp =  pt[0][:-1]\n",
    "        if tmp in nkeys:\n",
    "            pos.append(tmp)\n",
    "    \n",
    "    pos = pd.Series(pos).unique()\n",
    "    nn_content.append(\" \".join(pos))\n",
    "nn_contents = [n.split() for n in nn_content]\n",
    "print nn_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right approach write spin controller soccer robot\n",
      "p imagine programming 3 wheel soccer robot type controller would use spinning p pid p p goal controller make robot stand defined angle 0 degree turn back rotated hand robot p p use stepper motors robot servos need implement software p p written sample p type controller already movement fairly good would like make better possible code follows p pre code void spinspeed int devidedvalue int addedvalue int correction degree lt correction amp amp degree gt correction motorspeed 0 else degree gt 0 motorspeed degree devidedvalue addedvalue else motorspeed degree devidedvalue addedvalue code pre p code correction code range robot movement code degree code number 127 128 returned compass code motorspeed code number 0 255 applied pwm p\n",
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n",
      "['wheel', 'pid', 'motor', 'servos', 'software', 'movement', 'pwm']\n"
     ]
    }
   ],
   "source": [
    "print dataframes['robotics']['title'][0]\n",
    "print dataframes['robotics']['content'][0]\n",
    "print nn_titles[0]\n",
    "print nn_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_contents = [\" \".join(c) for c in nn_contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_titles = [\" \".join(c) for c in nn_titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approach spin controller soccer robot\n",
      "wheel pid motor servos software movement pwm\n",
      "approach spin controller soccer robotwheel pid motor servos software movement pwm\n"
     ]
    }
   ],
   "source": [
    "print nn_titles[0]\n",
    "print nn_contents[0]\n",
    "nn_tandc = []\n",
    "for idx,t in enumerate(nn_titles):\n",
    "    tmp = t+nn_contents[idx]\n",
    "    nn_tandc.append(tmp)\n",
    "print nn_tandc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_content_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_X = r_content_vectorizer.fit_transform(nn_tandc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X.toarray(), r_y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 915)\n",
      "(915, 98)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61200735316\n",
      "0.978275900524\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying all Tags with Bigrams and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r2g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_2g = r2g_title_vectorizer.fit_transform(r_titles)\n",
    "r_X_2t_array = r_X_2g.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "r_Y_array = r_Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X_2g.toarray(), r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 1856)\n"
     ]
    }
   ],
   "source": [
    "clf_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    clf_y.append(vec)\n",
    "clf_y = np.array(svm_y)\n",
    "print clf_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_array = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = GaussianNB()\n",
    "    try:\n",
    "        clf.fit(Xc_train, clf_y[t])\n",
    "        clf_array.append(clf)\n",
    "    except:\n",
    "        clf_array.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  17,   51,   62,  116,  129,  165,  195,  198,  299,  397,  466,\n",
      "        562,  605,  750,  786,  831,  966, 1000, 1057, 1064, 1165, 1278,\n",
      "       1286, 1354, 1391, 1483, 1518, 1521, 1544, 1587, 1589, 1640, 1642,\n",
      "       1720, 1745, 1790]),)\n"
     ]
    }
   ],
   "source": [
    "print clf_y[3].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in clf_array:\n",
    "    print '*',\n",
    "    if cl is not None:\n",
    "        y_pred = cl.predict(Xc_test)\n",
    "    else:\n",
    "        y_pred = [0]*Xc_test.shape[0]\n",
    "    out1.append(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 915)\n",
      "(915, 230)\n",
      "(array([149, 177, 322, 518, 674]),)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape\n",
    "print out1[0].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.577967447277\n",
      "0.979154193395\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGHCAYAAACAk0mtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBMkAEBOkAAAOUECAOQECQCQEyQAQG4DPqCC/eeTPk0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118a6d850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_tags_histo = [len(ttt.split()) for ttt in r_tags]\n",
    "plt.hist(r_tags_histo, bins='auto')\n",
    "plt.ylabel('number of questions')\n",
    "plt.xlabel('labels per question')\n",
    "plt.title('Number of labels per question')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refinement with SVM and Contents POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pid', 'motor', 'servos', 'software']\n"
     ]
    }
   ],
   "source": [
    "contents = dataframes['robotics']['content']\n",
    "nn_content = []\n",
    "for i,content in enumerate(contents):\n",
    "    pos = []\n",
    "    pt_cont = nltk.pos_tag(word_tokenize(content))\n",
    "    for pt in pt_cont:\n",
    "        #print(pt)\n",
    "        tmp = pt[0]\n",
    "        if pt[1]=='NNS':\n",
    "            tmp =  pt[0][:-1]\n",
    "        if tmp in keys:\n",
    "            pos.append(tmp)\n",
    "    \n",
    "    pos = pd.Series(pos).unique()\n",
    "    nn_content.append(\" \".join(pos))\n",
    "nn_contents = [n.split() for n in nn_content]\n",
    "print nn_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right approach write spin controller soccer robot pid motor servos software\n"
     ]
    }
   ],
   "source": [
    "#r_titles[0]+(\" \".join(nn_contents[0]))\n",
    "new_input = [el+\" \"+(\" \".join(nn_contents[idx])) for idx,el in enumerate(r_titles)]\n",
    "print new_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_X_2g = r2g_title_vectorizer.fit_transform(new_input)\n",
    "r_X_2t_array = r_X_2g.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "r_Y_array = r_Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test= train_test_split(r_X_2g.toarray(), r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 1856)\n"
     ]
    }
   ],
   "source": [
    "clf_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    clf_y.append(vec)\n",
    "clf_y = np.array(clf_y)\n",
    "print clf_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_array_2 = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    try:\n",
    "        clf.fit(Xc_train, svm_y[t])\n",
    "        clf_array_2.append(clf)\n",
    "    except:\n",
    "        clf_array_2.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in clf_array_2:\n",
    "    print '*',\n",
    "    if cl is not None:\n",
    "        y_pred = cl.predict(Xc_test)\n",
    "    else:\n",
    "        y_pred = [0]*Xc_test.shape[0]\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(230, 915)\n",
      "(915, 230)\n",
      "[ 62 159]\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print y_pred[0]\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    maxtags = 4\n",
    "    for idx,v in enumerate(vec):\n",
    "        if v==1:\n",
    "            maxtags = maxtags-1\n",
    "        if maxtags ==0:\n",
    "            v=0\n",
    "        vec[idx]=v\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape\n",
    "\n",
    "print res[310].nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657889575958\n",
      "0.991190306486\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/len(res))\n",
    "print(_ascore/len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unseen Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uq = []\n",
    "t1 = 'difference between sabertooth motor controller and rc esc?'\n",
    "c1 = 'i am building a rc/robot mower. most of the youtube videos show the sabertooth motor controllers being used to connect the rc receiver to the dc motors. But here in Australia, the sabertooth i need cost about 200 dollars. RC esc sell for about 10 dollars. What is the difference between the esc and the sabertooth and can i use an esc instead?the specs i have on the motor and battery are 12v 10amp normal, 35amp stall. and my rc is a flysky'\n",
    "q={'title':t1,'content':c1}\n",
    "uq.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
