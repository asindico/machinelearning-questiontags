{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Questions Automatic Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Capstone Project of my Udacity Machine Learning Nano Degree.\n",
    "\n",
    "In this capstone project I will focus on one specific kind of problem among the many open problems in NLP: Text Classification. The task is to state what is the topic, among several availables, of a content expressed in natural language. To this end I will rely on the questions shared by Stack Exchange , take three classes of questions (i.e. cooking, robotics, biology) and try to create a model capable of stating to what of these three classes an unknown question belongs. After that I will try to create a model that for the questions of a given topic tries to predict what are the tags that best describe it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    \"cooking\": pd.read_csv(\"cooking.csv\"),\n",
    "    \"biology\": pd.read_csv(\"biology.csv\"),\n",
    "    \"robotics\": pd.read_csv(\"robotics.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes['cooking']['class'] = 'cooking'\n",
    "dataframes['biology']['class'] = 'biology'\n",
    "dataframes['robotics']['class'] = 'robotics'\n",
    "\n",
    "allquestions = pd.concat([dataframes['cooking'][:5000],dataframes['robotics'],dataframes['biology'][:5000]],\n",
    "                        ignore_index=True)\n",
    "#allquestions = allquestions.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                         2\n",
      "title                    How should I cook bacon in an oven?\n",
      "content    <p>I've heard of people cooking bacon in an ov...\n",
      "tags                                 oven cooking-time bacon\n",
      "class                                                cooking\n",
      "Name: 1, dtype: object\n",
      "id                                                         2\n",
      "title      How can I modify a low cost hobby servo to run...\n",
      "content    <p>I've got some hobby servos (<a href=\"http:/...\n",
      "tags                                         control rcservo\n",
      "class                                               robotics\n",
      "Name: 1, dtype: object\n",
      "id                                                         2\n",
      "title      How is RNAse contamination in RNA based experi...\n",
      "content    <p>Does anyone have any suggestions to prevent...\n",
      "tags                                        rna biochemistry\n",
      "class                                                biology\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].iloc[1])\n",
    "print(dataframes[\"robotics\"].iloc[1])\n",
    "print(dataframes[\"biology\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15404, 5)\n",
      "['baking', 'food-safety', 'substitutions', 'equipment', 'bread']\n",
      "[1444, 1211, 920, 816, 687]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBESOAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117919f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].shape)\n",
    "ctags = [ti for ta in dataframes[\"cooking\"].tags for ti in ta.split() ]\n",
    "cseries = pd.Series(ctags)\n",
    "cus = cseries.unique()\n",
    "counter = Counter(cseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "print(cus.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 5)\n",
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor']\n",
      "[306, 295, 282, 255, 239]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBUxNEiSpCKGBkmSVOT/A3Gunpk67gabAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117a56410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"robotics\"].shape)\n",
    "rtags = [ti for ta in dataframes[\"robotics\"].tags for ti in ta.split() ]\n",
    "rseries = pd.Series(rtags)\n",
    "counter = Counter(rseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "rdf = pd.DataFrame(counter)\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "rus = rseries.unique()\n",
    "print(rus.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13196, 5)\n",
      "['human-biology', 'genetics', 'evolution', 'biochemistry', 'molecular-biology']\n",
      "[1448, 1229, 1159, 984, 863]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c72b350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"biology\"].shape)\n",
    "btags = [ti for ta in dataframes[\"biology\"].tags for ti in ta.split() ]\n",
    "bseries = pd.Series(btags)\n",
    "counter = Counter(bseries)\n",
    "counter = counter.most_common()\n",
    "keys = [c[0] for c in counter][:50]\n",
    "counts = [c[1] for c in counter][:50]\n",
    "print(keys[:5])\n",
    "print(counts[:5])\n",
    "plt.bar(range(len(keys)), counts, align='center')\n",
    "plt.show()\n",
    "bus = bseries.unique()\n",
    "print(bus.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we have to do is transforming the input text into something that is machine readble which basically means numbers. \n",
    "We have to drop all the elemnts that do not provide relevant information. Since questions titles may contains html tags and uris we have to remove them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))'\n",
    "def stripTagsAndUris(x):\n",
    "    if x:\n",
    "        soup = BeautifulSoup(x, \"html.parser\")\n",
    "        if soup.code:\n",
    "            soup.code.decompose()\n",
    "        text =  soup.get_text()\n",
    "        return re.sub(uri_re, \"\", text)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removePunctuation(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
    "    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "def removeStopwords(x):\n",
    "    filtered_words = [word for word in x.split() if word not in stops]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textprep(_df):\n",
    "    for df in _df.values():\n",
    "        df[\"content\"] = df[\"title\"].map(stripTagsAndUris)\n",
    "    for df in _df.values():\n",
    "        df[\"title\"] = df[\"title\"].map(removePunctuation)\n",
    "        df[\"title\"] = df[\"title\"].map(removeStopwords)\n",
    "        df[\"content\"] = df[\"content\"].map(removePunctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textprep(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                           2\n",
      "title                          cook bacon oven\n",
      "content    how should i cook bacon in an oven \n",
      "tags                   oven cooking-time bacon\n",
      "class                                  cooking\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframes[\"cooking\"].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest approach is the so called Bag-of-words model where the text is represented by the set of words contained in it, loosing their order and thus disregarding the grammar or the syntax. Each word is paired with an integer representing the occurrencies of that word in the represented text. One of the weak aspect of this approach is that longer text may present more occurrencies of a given word, with respect to a shorter text, not because of its relevance but just because the text is longer. \n",
    "\n",
    "Since we rely in titles, which are short by construction, I think this aspect will not affect our task.\n",
    "\n",
    "We rely on scikit learn CountVectorizer to transform words into numbers. We use a custom token pattern in order to catch words containing the '-' character like 'cooking-time'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing cooking titles\n",
      "vectorizing robotics titles\n",
      "vectorizing biology titles\n",
      "vectorizing cooking tags\n",
      "vectorizing robotics tags\n",
      "vectorizing biology tags\n",
      "vectorizing all titles\n"
     ]
    }
   ],
   "source": [
    "c_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "c_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "b_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "b_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "\n",
    "a_title_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "a_tag_vectorizer   = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "\n",
    "c_titles = dataframes['cooking']['title']\n",
    "r_titles = dataframes['robotics']['title']\n",
    "b_titles = dataframes['biology']['title']\n",
    "\n",
    "c_tags = dataframes['cooking']['tags']\n",
    "r_tags = dataframes['robotics']['tags']\n",
    "b_tags = dataframes['biology']['tags']\n",
    "\n",
    "a_titles  = allquestions['title']\n",
    "a_classes = allquestions['class']\n",
    "\n",
    "print \"vectorizing cooking titles\"\n",
    "c_X = c_title_vectorizer.fit_transform(c_titles)\n",
    "print \"vectorizing robotics titles\"\n",
    "r_X = r_title_vectorizer.fit_transform(r_titles)\n",
    "print \"vectorizing biology titles\"\n",
    "b_X = b_title_vectorizer.fit_transform(b_titles)\n",
    "\n",
    "print \"vectorizing cooking tags\"\n",
    "c_Y = c_tag_vectorizer.fit_transform(c_tags)\n",
    "print \"vectorizing robotics tags\"\n",
    "r_Y = r_tag_vectorizer.fit_transform(r_tags)\n",
    "print \"vectorizing biology tags\"\n",
    "b_Y = b_tag_vectorizer.fit_transform(b_tags)\n",
    "\n",
    "print \"vectorizing all titles\"\n",
    "a_X = a_title_vectorizer.fit_transform(a_titles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2573)\t1\n",
      "  (0, 1974)\t1\n",
      "  (0, 1990)\t1\n",
      "  (0, 1937)\t1\n"
     ]
    }
   ],
   "source": [
    "print(a_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of single words like the bag-of-words fail capture phrases and expressions of multiple words. A more valuable approch is to consider single words along with sequences of adjcent words called n-grams. In this project we use bi-grams as a possible input model. Fortunately the CountVectorizer class can be configured to extract any range of ngram with the ngram_range(min,max) option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing all titles with 3-grams\n"
     ]
    }
   ],
   "source": [
    "ang_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing all titles with 2-grams\"\n",
    "a_X_2g = ang_title_vectorizer.fit_transform(a_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8358)\t1\n",
      "  (0, 8419)\t1\n",
      "  (0, 8143)\t1\n",
      "  (0, 11082)\t1\n",
      "  (0, 8355)\t1\n",
      "  (0, 8405)\t1\n",
      "  (0, 8141)\t1\n"
     ]
    }
   ],
   "source": [
    "print(a_X_2g[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more sophisticated approach is to rely on vector space representations of words. Basically the idea is to exploit a previously created lookup table in which, for each word of our vocabulary, a vector of float valus corresponds. Their interesting property is that two words with similar meaning have similar vectors. These vectors are generally created automatically with a separated machine learning approach on big corpus of texts. \n",
    "In this project we rely on an already exsiting vector space called Glove.\n",
    "\n",
    "https://nlp.stanford.edu/pubs/glove.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = {}\n",
    "with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here follows an example of what the pre-trained data can be used to retrieve vectors of values for each single word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68163   1.1578   -0.47827   0.41421  -0.53186   0.63827  -0.90381\n",
      "  0.50795   0.057398 -0.29163   1.1411   -0.079702  0.19951   1.1925\n",
      "  0.52281   0.78633   0.78555   0.32624  -1.5504   -1.0191    0.35532\n",
      " -0.38875   0.92789   0.24325  -0.43162  -0.54939  -0.52209   1.0721\n",
      "  0.99558  -0.38605   2.2673    0.41067  -0.08973   0.29741  -0.18678\n",
      "  0.44329  -0.42243   0.80558   1.1306    0.14038  -0.089723  0.1341\n",
      "  0.47948  -0.12774   0.024234  0.051782  0.44778  -0.47974  -0.62491\n",
      " -0.90005 ]\n"
     ]
    }
   ],
   "source": [
    "keys= w2v.keys()\n",
    "print (w2v['ice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_Xe = []\n",
    "for title in a_titles:\n",
    "    sentence = []\n",
    "    for word in title.split():\n",
    "        if word in w2v:\n",
    "            wv = w2v[word]\n",
    "            sentence.append(wv)\n",
    "    words = [w for s in sentence for w in s]\n",
    "    a_Xe.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "maxdim = 0\n",
    "for s in a_Xe:\n",
    "    if len(s)>maxdim:\n",
    "        maxdim = len(s)\n",
    "print maxdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for sent in a_Xe:\n",
    "    padd = [0 for _ in range (maxdim - len(sent))]\n",
    "    padd = np.asarray(padd)\n",
    "    paddedsent = np.concatenate((sent,padd),axis=0)\n",
    "    sentences.append(paddedsent)\n",
    "a_Xe = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35145   -0.24155    0.0054776 ...,  0.         0.         0.       ]\n"
     ]
    }
   ],
   "source": [
    "print a_Xe[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Problem: Questions Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first problem I will try to create a model capable of stating, given an unknown question, to what class it belongs. I will try Naive Bayes and Random Forest on input data modeled through Bag of Words, n-grams (with n = 2) and word vectors (Glove). In the third case I will also try to train a Convolutional Neural Network. \n",
    "\n",
    "I will compare the obtained 7 models through the F1score metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12771, 12661)\n"
     ]
    }
   ],
   "source": [
    "print a_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a_X.toarray(), a_classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology\n",
      "biology\n"
     ]
    }
   ],
   "source": [
    "idx = 351\n",
    "print np.array(y_test)[idx]\n",
    "print y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887763885977\n"
     ]
    }
   ],
   "source": [
    "fs1_1 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877509953024\n"
     ]
    }
   ],
   "source": [
    "fs1_2 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 2-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12771, 55882)\n",
      "(12771,)\n"
     ]
    }
   ],
   "source": [
    "a_X_2g_array = a_X_2g.toarray()\n",
    "print(a_X_2g_array.shape)\n",
    "print(a_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3g_train, X3g_test, y3g_train, y3g_test = train_test_split(a_X_2g_array, a_classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb3 = GaussianNB()\n",
    "y_pred = gnb3.fit(X3g_train, y3g_train).predict(X3g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896844697847\n"
     ]
    }
   ],
   "source": [
    "fs1_3 = f1_score(np.array(y3g_test), y_pred, average='macro') \n",
    "print fs1_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X3g_train, y3g_train).predict(X3g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.878467432249\n"
     ]
    }
   ],
   "source": [
    "fs1_4 = f1_score(np.array(y3g_test), y_pred, average='macro') \n",
    "print fs1_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_classes = a_classes.str.get_dummies()\n",
    "#print cat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(a_Xe, a_classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(a_Xe, cat_classes, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.149552249279\n"
     ]
    }
   ],
   "source": [
    "fs1_5 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707805926699\n"
     ]
    }
   ],
   "source": [
    "fs1_6 = f1_score(np.array(y_test), y_pred, average='macro') \n",
    "print fs1_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3970 - acc: 0.8319    \n",
      "Epoch 2/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3860 - acc: 0.8365    \n",
      "Epoch 3/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3733 - acc: 0.8375    \n",
      "Epoch 4/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3636 - acc: 0.8434    \n",
      "Epoch 5/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3514 - acc: 0.8511    \n",
      "Epoch 6/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.3424 - acc: 0.8574    \n",
      "Epoch 7/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3318 - acc: 0.8620    \n",
      "Epoch 8/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3217 - acc: 0.8622    \n",
      "Epoch 9/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.3111 - acc: 0.8717    \n",
      "Epoch 10/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.3039 - acc: 0.8706    \n",
      "Epoch 11/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2952 - acc: 0.8742    \n",
      "Epoch 12/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2838 - acc: 0.8793    \n",
      "Epoch 13/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2774 - acc: 0.8828    \n",
      "Epoch 14/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2734 - acc: 0.8852    \n",
      "Epoch 15/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2631 - acc: 0.8891    \n",
      "Epoch 16/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.2551 - acc: 0.8928    \n",
      "Epoch 17/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2487 - acc: 0.8946    \n",
      "Epoch 18/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2442 - acc: 0.8977    \n",
      "Epoch 19/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2338 - acc: 0.9017    \n",
      "Epoch 20/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.2270 - acc: 0.9038    \n",
      "Epoch 21/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2215 - acc: 0.9050    \n",
      "Epoch 22/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.2186 - acc: 0.9047    \n",
      "Epoch 23/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.2123 - acc: 0.9090    \n",
      "Epoch 24/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.2046 - acc: 0.9113    \n",
      "Epoch 25/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.1995 - acc: 0.9140    \n",
      "Epoch 26/40\n",
      "8556/8556 [==============================] - 16s - loss: 0.1968 - acc: 0.9154    \n",
      "Epoch 27/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.1903 - acc: 0.9156    \n",
      "Epoch 28/40\n",
      "8556/8556 [==============================] - 15s - loss: 0.1902 - acc: 0.9182    \n",
      "Epoch 29/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1854 - acc: 0.9184    \n",
      "Epoch 30/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1814 - acc: 0.9213    \n",
      "Epoch 31/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1754 - acc: 0.9237    \n",
      "Epoch 32/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1761 - acc: 0.9247    \n",
      "Epoch 33/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1683 - acc: 0.9279    \n",
      "Epoch 34/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1672 - acc: 0.9264    \n",
      "Epoch 35/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1619 - acc: 0.9298    \n",
      "Epoch 36/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1589 - acc: 0.9312    \n",
      "Epoch 37/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.1560 - acc: 0.9312    \n",
      "Epoch 38/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1513 - acc: 0.9343    \n",
      "Epoch 39/40\n",
      "8556/8556 [==============================] - 13s - loss: 0.1505 - acc: 0.9348    \n",
      "Epoch 40/40\n",
      "8556/8556 [==============================] - 14s - loss: 0.1502 - acc: 0.9327    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124fc1cd0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "try:\n",
    "    model = load_model(\"cnn_nlp_5.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((50,maxdim/50,1), input_shape=(maxdim,)))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_nlp_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4160/4215 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "robotics\n"
     ]
    }
   ],
   "source": [
    "print y_pred[3].argmax()\n",
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    r = y.argmax()\n",
    "    if r ==0:\n",
    "        _y_pred.append('biology')\n",
    "    if r ==1:\n",
    "        _y_pred.append('cooking')\n",
    "    if r ==2:\n",
    "        _y_pred.append('robotics')\n",
    "print _y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765472738448\n"
     ]
    }
   ],
   "source": [
    "fs1_7 = f1_score(np.array(y_test), _y_pred, average='macro') \n",
    "print fs1_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part of the capstone project I have investigated three different approches to transform input text into valuable inputs for machine learning algorithms: Bag-of-words, in which single words are taken, turned into integers and paired with the number of occurencies they have in each single sentence; 2-grams, in which the same thing is done for sequences of 2 words occurring in the same sentence; words vectors, in which any word is turned into a vector of floating values calculated trhough a previous automatic elebaboration of a corpus so that semantically similar words show similar vectors.\n",
    "\n",
    "I have applied Naive Bayes and Random Forest for each Input model in order to see what combination performed better in classifing cooking, robotics and biology questions.\n",
    "\n",
    "It turned out the best solution is Nayve Bayes trained on bi-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Input Model              ML Model    Result\n",
      "0  Bag of Words           Naive Bayes  0.887764\n",
      "1  Bag of Words         Random Forest  0.877510\n",
      "2       2_GRAMS           Naive Bayes  0.896845\n",
      "3       2_GRAMS         Random Forest  0.878467\n",
      "4   WordVectors           Naive Bayes  0.149552\n",
      "5   WordVectors         Random Forest  0.707806\n",
      "6   WordVectors  Conv. Neural Network  0.765473\n"
     ]
    }
   ],
   "source": [
    "result = [['Bag of Words','Naive Bayes',fs1_1],['Bag of Words','Random Forest',fs1_2],\n",
    "          ['2_GRAMS','Naive Bayes',fs1_3],['2_GRAMS','Random Forest',fs1_4],\n",
    "          ['WordVectors','Naive Bayes',fs1_5],['WordVectors','Random Forest',fs1_6],\n",
    "          ['WordVectors','Conv. Neural Network',fs1_7]]\n",
    "result = pd.DataFrame(result,columns=[\"Input Model\",\"ML Model\",\"Result\"])\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try the best model on my own questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model succeds in classifying made up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_topic(q):\n",
    "    q = removePunctuation(q)\n",
    "    q = removeStopwords(q)\n",
    "    q =  ang_title_vectorizer.transform([q])\n",
    "    q = q.toarray()\n",
    "    answer = gnb3.predict(q)\n",
    "    return answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cooking\n",
      "biology\n",
      "robotics\n"
     ]
    }
   ],
   "source": [
    "print question_topic('at what temperature should I bake bread?')\n",
    "print question_topic('how high can a frog jump?')\n",
    "print question_topic('how many cameras do I need to create a 3d image?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Problem: Tagging Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we are going to focus on questions of a single topic and try to create a model capable of assigning tags to unknown questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771,)\n"
     ]
    }
   ],
   "source": [
    "robotics_questions = dataframes['robotics']['title']\n",
    "robotics_questions.head()\n",
    "print robotics_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "robotics_tags = dataframes['robotics']['tags']\n",
    "rtags = [ti for ta in dataframes[\"robotics\"].tags for ti in ta.split() ]\n",
    "rseries = pd.Series(rtags)\n",
    "counter = Counter(rseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor']\n",
      "[306, 295, 282, 255, 239]\n",
      "239\n",
      "4613\n"
     ]
    }
   ],
   "source": [
    "counter = counter.most_common()\n",
    "maxcount = 50\n",
    "keys = [c[0] for c in counter][:maxcount]\n",
    "counts = [c[1] for c in counter][:maxcount]\n",
    "\n",
    "print keys[:5]\n",
    "print counts[:5]\n",
    "print counts[4]\n",
    "\n",
    "count = 0\n",
    "for c in counts:\n",
    "    count=count+c\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc_tags_vectorizer = CountVectorizer(stop_words='english',token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "rc_tags = rc_tags_vectorizer.fit_transform(r_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nouns Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple benchmark model I am going to extract nouns and gerunds from questions and use them as possible tags. We rely on the pos_tag function (which means 'parts of speech tagging') of the nltk library to extract Nouns and Gerunds and see how this straightforward approach performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_titles = []\n",
    "for i,title in enumerate(r_titles):\n",
    "    pos = []\n",
    "    pt_titl = nltk.pos_tag(word_tokenize(title))\n",
    "    for pt in pt_titl:\n",
    "        #print(pt)\n",
    "        if pt[1]=='NN':\n",
    "            pos.append(pt[0])\n",
    "            #pos.append(pt[0]+'s')\n",
    "        if pt[1]=='NNS':\n",
    "            #pos.append(pt[0])\n",
    "            pos.append(pt[0][:-1])\n",
    "        if pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS':\n",
    "            pos.append(pt[0])\n",
    "    nn_titles.append(\" \".join(pos))\n",
    "nn_titles = [n.split() for n in nn_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the following example shows this approach is very simple but can provide interesting results we are now going to measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['approach', 'spin', 'controller', 'soccer', 'robot']\n",
      "['soccer', 'control']\n"
     ]
    }
   ],
   "source": [
    "print nn_titles[0]\n",
    "print r_tags[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec_tags = []\n",
    "for nl in nn_titles:\n",
    "    vt = [0]*rc_tags.shape[1]\n",
    "    for n in nl:\n",
    "        if n in rc_tags_vectorizer.vocabulary_:\n",
    "            vt[rc_tags_vectorizer.vocabulary_.get(n)]=1\n",
    "    vec_tags.append(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(array([123]),)\n",
      "(array([ 10, 123, 164]),)\n",
      "---\n",
      "(array([193]),)\n",
      "(array([148, 193]),)\n",
      "---\n",
      "(array([192]),)\n",
      "(array([122, 192]),)\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()\n",
    "idx = 5\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()\n",
    "idx = 9\n",
    "print \"---\"\n",
    "print np.array(vec_tags[idx]).nonzero()\n",
    "print np.array(rc_tags.toarray()[idx]).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an average of 0.6 for the f1 score metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608191533899\n"
     ]
    }
   ],
   "source": [
    "rc_tags_array = rc_tags.toarray()\n",
    "_score = 0\n",
    "for i,el in enumerate(rc_tags_array):\n",
    "    _score+= f1_score(el,vec_tags[i], average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to do something more sophisticated. We have seen word of vectors performed poorly with CNN for the first classification problem. I'd like now to create a CNN capable of tagging questions better that our NNs based approach (f1_score > 0.6) through word of vectors and I think an improvement could com from creating word vectors from titles' Nouns and Verbs only (avoiding any other POS TAG). \n",
    "\n",
    "Let's see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_Xe = []\n",
    "for title in nn_titles:\n",
    "    sentence = []\n",
    "    for word in title:\n",
    "        if word in w2v:\n",
    "            wv = w2v[word]\n",
    "            sentence.append(wv)\n",
    "    words = [w for s in sentence for w in s]\n",
    "    a_Xe.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "maxdim = 0\n",
    "for s in a_Xe:\n",
    "    if len(s)>maxdim:\n",
    "        maxdim = len(s)\n",
    "print maxdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences =[]\n",
    "for sent in a_Xe:\n",
    "    padd = [0 for _ in range (maxdim - len(sent))]\n",
    "    padd = np.asarray(padd)\n",
    "    paddedsent = np.concatenate((sent,padd),axis=0)\n",
    "    sentences.append(paddedsent)\n",
    "a_Xe = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_Y.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(a_Xe, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 230)\n",
      "(1856, 600)\n"
     ]
    }
   ],
   "source": [
    "print yc_train.shape\n",
    "print np.array(Xc_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5415 - acc: 0.5474     \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5358 - acc: 0.5544     \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5310 - acc: 0.5453     \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5200 - acc: 0.5528     \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5234 - acc: 0.5673     \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5075 - acc: 0.5544     \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5049 - acc: 0.5673     \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.5017 - acc: 0.5463     \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.4998 - acc: 0.5506     \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 4s - loss: 2.4901 - acc: 0.5388     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1acaf5ad0>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "try:\n",
    "    model = load_model(\"cnn_tags_2.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((maxdim/50,50,1), input_shape=(maxdim,)))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(Convolution2D(16, 3, 3,activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(230, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_tags_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWord(_idx):\n",
    "    for word,idx in r_tag_vectorizer.vocabulary_.iteritems():\n",
    "        if idx == _idx:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.1:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.195349315056\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained the CNN for 40 epochs and the final average f1_score result is about 0.2. I will try with a bi-grams input model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trying with bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing robotics titles with 2-grams\n"
     ]
    }
   ],
   "source": [
    "r3g_title_vectorizer = CountVectorizer(stop_words='english',ngram_range=(1, 2),\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "print \"vectorizing robotics titles with 2-grams\"\n",
    "r_X_3g = r3g_title_vectorizer.fit_transform(r_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_Y.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 100s - loss: 2.5049 - acc: 0.5603   \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 111s - loss: 2.4899 - acc: 0.5668   \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 98s - loss: 2.4552 - acc: 0.5684    \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 97s - loss: 2.4504 - acc: 0.5598    \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 106s - loss: 2.4230 - acc: 0.5620   \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 111s - loss: 2.4212 - acc: 0.5603   \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 108s - loss: 2.4032 - acc: 0.5706   \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 99s - loss: 2.3993 - acc: 0.5512    \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 99s - loss: 2.3908 - acc: 0.5663    \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 98s - loss: 2.3835 - acc: 0.5620    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131df3610>"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model,Sequential\n",
    "from keras.layers.core import Reshape,Flatten,Dense\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.models import load_model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "maxdim = Xc_train.shape[1]\n",
    "try:\n",
    "    model = load_model(\"cnn_tags_3g_1.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxdim,15,input_length=maxdim))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(230, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_tags_3g_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 8s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.204231566286\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the obtaind result is very similar to previous one meaning the bi-grams input model didn't affect the performance. I will try with random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### back to Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1856, 13343)\n",
      "(1856, 230)\n"
     ]
    }
   ],
   "source": [
    "print Xc_train.shape\n",
    "print yc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(Xc_train, yc_train).predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n",
      "0.196631592143\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the result is about 0.2. Are we dealing with too much tags? Considering how unbalanced the tags are we might have better results if we focused on the most relevant 50 tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying reducing tags and deal with the 50 most relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_top50_tags = []\n",
    "for tags in r_tags:\n",
    "    nr = ''\n",
    "    for tag in word_tokenize(tags):\n",
    "        if tag in keys:\n",
    "            nr+=tag+' '\n",
    "    r_top50_tags.append(nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control ', 'control rcservo ', '', ..., 'arduino raspberry-pi ',\n",
       "       'slam ekf ', ''], \n",
       "      dtype='|S76')"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(r_top50_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_50tag_vectorizer = CountVectorizer(stop_words='english',\n",
    "                                       token_pattern=r'\\b\\w\\w+-?\\w+\\b')\n",
    "r_top50_tags = r_50tag_vectorizer.fit_transform(np.array(r_top50_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 50)"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_top50_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quadcopter', 'mobile-robot', 'arduino', 'control', 'motor', 'sensors', 'robotic-arm', 'pid', 'localization', 'microcontroller', 'slam', 'ros', 'raspberry-pi', 'irobot-create', 'wheeled-robot', 'design', 'kinematics', 'kalman-filter', 'computer-vision', 'imu', 'motion-planning', 'inverse-kinematics', 'mechanism', 'brushless-motor', 'battery', 'power', 'cameras', 'stepper-motor', 'electronics', 'accelerometer', 'navigation', 'software', 'kinect', 'servos', 'algorithm', 'gyroscope', 'actuator', 'matlab', 'dynamics', 'ekf', 'servomotor', 'sensor-fusion', 'torque', 'mapping', 'esc', 'rcservo', 'industrial-robot', 'gps', 'odometry', 'stereo-vision']\n"
     ]
    }
   ],
   "source": [
    "print keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_top50_tags.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Model\n",
      "Epoch 1/10\n",
      "1856/1856 [==============================] - 41s - loss: 6.2013 - acc: 0.0528    \n",
      "Epoch 2/10\n",
      "1856/1856 [==============================] - 42s - loss: 6.0832 - acc: 0.0749    \n",
      "Epoch 3/10\n",
      "1856/1856 [==============================] - 42s - loss: 4.5918 - acc: 0.3367    \n",
      "Epoch 4/10\n",
      "1856/1856 [==============================] - 39s - loss: 2.6521 - acc: 0.5393    \n",
      "Epoch 5/10\n",
      "1856/1856 [==============================] - 38s - loss: 1.9470 - acc: 0.5792    \n",
      "Epoch 6/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.6414 - acc: 0.6002    \n",
      "Epoch 7/10\n",
      "1856/1856 [==============================] - 42s - loss: 1.5333 - acc: 0.5991    \n",
      "Epoch 8/10\n",
      "1856/1856 [==============================] - 40s - loss: 1.4773 - acc: 0.6013    \n",
      "Epoch 9/10\n",
      "1856/1856 [==============================] - 41s - loss: 1.4361 - acc: 0.5911    \n",
      "Epoch 10/10\n",
      "1856/1856 [==============================] - 39s - loss: 1.4084 - acc: 0.6137    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b27bfed0>"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxdim = Xc_train.shape[1]\n",
    "try:\n",
    "    model = load_model(\"cnn_50tags_3g_1.h5\")\n",
    "except:\n",
    "    print(\"Creating new Model\")\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(maxdim,15,input_length=maxdim))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    model.add(Convolution1D(16, 3,activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation ='softmax'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "model.fit(np.array(Xc_train), np.array(yc_train), batch_size=32,verbose=1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_50tags_3g_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915/915 [==============================] - 8s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(np.array(Xc_test),batch_size=32,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "0.214709215698\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the result is basically the same with a 0.01 of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top 50 with random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20,criterion='entropy')\n",
    "y_pred = clf.fit(Xc_train, yc_train).predict(Xc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_y_pred= []\n",
    "for y in y_pred:\n",
    "    ny = [0]*len(y)\n",
    "    for i,v in enumerate(y):\n",
    "        if v > 0.16:\n",
    "            ny[i]=1\n",
    "    _y_pred.append(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "0.32\n",
      "0.214355330127\n"
     ]
    }
   ],
   "source": [
    "print len(yc_test[0])\n",
    "print len(y_pred[0])\n",
    "\n",
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(_y_pred):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_ascore/rc_tags.shape[0])\n",
    "print(_score/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_Y_array = r_top50_tags.toarray()\n",
    "r_X_3g_array = r_X_3g.toarray()\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(r_X_3g_array, r_Y_array, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 50)\n"
     ]
    }
   ],
   "source": [
    "print r_Y_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1856)\n"
     ]
    }
   ],
   "source": [
    "svm_y = []\n",
    "for t in range(yc_train.shape[1]):\n",
    "    vec = [yc_train[q,t] for q in range(yc_train.shape[0])]\n",
    "    svm_y.append(vec)\n",
    "svm_y = np.array(svm_y)\n",
    "print svm_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-736-6bf9ec6cd481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msvm_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_array = []\n",
    "for t in range(rc_tags.shape[1]-1):\n",
    "    print t,\n",
    "    clf = svm.LinearSVC()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    svm_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-741-f226b7bb8932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mgnb_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "gnb_array = []\n",
    "for t in range(rc_tags.shape[1]-1):\n",
    "    print t,\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(Xc_train, svm_y[t])\n",
    "    gnb_array.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in svm_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "out1 = []\n",
    "for cl in gnb_array:\n",
    "    print '*',\n",
    "    y_pred = cl.predict(Xc_test)\n",
    "    out1.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 915)\n",
      "(915, 50)\n"
     ]
    }
   ],
   "source": [
    "out1 = np.array(out1)\n",
    "print out1.shape\n",
    "res = []\n",
    "for q in range(out1.shape[1]):\n",
    "    vec = [out1[t,q] for t in range(out1.shape[0])]\n",
    "    res.append(vec)\n",
    "res = np.array(res)\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22813426532\n",
      "0.321017683147\n"
     ]
    }
   ],
   "source": [
    "_score = 0\n",
    "_ascore =0\n",
    "for i,el in enumerate(res):\n",
    "    _ascore += accuracy_score(yc_test[i], el)\n",
    "    _score+= f1_score(yc_test[i],el, average='macro')\n",
    "print(_score/rc_tags.shape[0])\n",
    "print(_ascore/rc_tags.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have defined a benchmark model based on the extraction of nouns and verbs from titles which scored 0.6 for the average f1_score metric. I have trained several models with different input models which didin't manage to score more than 0.21."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
